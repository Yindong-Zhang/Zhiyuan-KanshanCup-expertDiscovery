{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 尝试对文本做LSA，没有完成\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel,LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICTLENGTH= 20000\n",
    "SVDSIZE= 128\n",
    "\n",
    "dataDir= '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(os.path.join())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dictionary in module gensim.corpora.dictionary:\n",
      "\n",
      "class Dictionary(gensim.utils.SaveLoad, collections.abc.Mapping)\n",
      " |  Dictionary encapsulates the mapping between normalized words and their integer ids.\n",
      " |  \n",
      " |  Notable instance attributes:\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  token2id : dict of (str, int)\n",
      " |      token -> tokenId.\n",
      " |  id2token : dict of (int, str)\n",
      " |      Reverse mapping for token2id, initialized in a lazy manner to save memory (not created until needed).\n",
      " |  cfs : dict of (int, int)\n",
      " |      Collection frequencies: token_id -> how many instances of this token are contained in the documents.\n",
      " |  dfs : dict of (int, int)\n",
      " |      Document frequencies: token_id -> how many documents contain this token.\n",
      " |  num_docs : int\n",
      " |      Number of documents processed.\n",
      " |  num_pos : int\n",
      " |      Total number of corpus positions (number of processed words).\n",
      " |  num_nnz : int\n",
      " |      Total number of non-zeroes in the BOW matrix (sum of the number of unique\n",
      " |      words per document over the entire corpus).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dictionary\n",
      " |      gensim.utils.SaveLoad\n",
      " |      collections.abc.Mapping\n",
      " |      collections.abc.Collection\n",
      " |      collections.abc.Sized\n",
      " |      collections.abc.Iterable\n",
      " |      collections.abc.Container\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, tokenid)\n",
      " |      Get the string token that corresponds to `tokenid`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tokenid : int\n",
      " |          Id of token.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Token corresponding to `tokenid`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If this Dictionary doesn't contain such `tokenid`.\n",
      " |  \n",
      " |  __init__(self, documents=None, prune_at=2000000)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      documents : iterable of iterable of str, optional\n",
      " |          Documents to be used to initialize the mapping and collect corpus statistics.\n",
      " |      prune_at : int, optional\n",
      " |          Dictionary will try to keep no more than `prune_at` words in its mapping, to limit its RAM\n",
      " |          footprint, the correctness is not guaranteed.\n",
      " |          Use :meth:`~gensim.corpora.dictionary.Dictionary.filter_extremes` to perform proper filtering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> texts = [['human', 'interface', 'computer']]\n",
      " |          >>> dct = Dictionary(texts)  # initialize a Dictionary\n",
      " |          >>> dct.add_documents([[\"cat\", \"say\", \"meow\"], [\"dog\"]])  # add more document (extend the vocabulary)\n",
      " |          >>> dct.doc2bow([\"dog\", \"computer\", \"non_existent_word\"])\n",
      " |          [(0, 1), (6, 1)]\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over all tokens.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Get number of stored tokens.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Number of stored tokens.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_documents(self, documents, prune_at=2000000)\n",
      " |      Update dictionary from a collection of `documents`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      documents : iterable of iterable of str\n",
      " |          Input corpus. All tokens should be already **tokenized and normalized**.\n",
      " |      prune_at : int, optional\n",
      " |          Dictionary will try to keep no more than `prune_at` words in its mapping, to limit its RAM\n",
      " |          footprint, the correctness is not guaranteed.\n",
      " |          Use :meth:`~gensim.corpora.dictionary.Dictionary.filter_extremes` to perform proper filtering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [\"máma mele maso\".split(), \"ema má máma\".split()]\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> len(dct)\n",
      " |          5\n",
      " |          >>> dct.add_documents([[\"this\", \"is\", \"sparta\"], [\"just\", \"joking\"]])\n",
      " |          >>> len(dct)\n",
      " |          10\n",
      " |  \n",
      " |  compactify(self)\n",
      " |      Assign new word ids to all words, shrinking any gaps.\n",
      " |  \n",
      " |  doc2bow(self, document, allow_update=False, return_missing=False)\n",
      " |      Convert `document` into the bag-of-words (BoW) format = list of `(token_id, token_count)` tuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      document : list of str\n",
      " |          Input document.\n",
      " |      allow_update : bool, optional\n",
      " |          Update self, by adding new tokens from `document` and updating internal corpus statistics.\n",
      " |      return_missing : bool, optional\n",
      " |          Return missing tokens (tokens present in `document` but not in self) with frequencies?\n",
      " |      \n",
      " |      Return\n",
      " |      ------\n",
      " |      list of (int, int)\n",
      " |          BoW representation of `document`.\n",
      " |      list of (int, int), dict of (str, int)\n",
      " |          If `return_missing` is True, return BoW representation of `document` + dictionary with missing\n",
      " |          tokens and their frequencies.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>> dct = Dictionary([\"máma mele maso\".split(), \"ema má máma\".split()])\n",
      " |          >>> dct.doc2bow([\"this\", \"is\", \"máma\"])\n",
      " |          [(2, 1)]\n",
      " |          >>> dct.doc2bow([\"this\", \"is\", \"máma\"], return_missing=True)\n",
      " |          ([(2, 1)], {u'this': 1, u'is': 1})\n",
      " |  \n",
      " |  doc2idx(self, document, unknown_word_index=-1)\n",
      " |      Convert `document` (a list of words) into a list of indexes = list of `token_id`.\n",
      " |      Replace all unknown words i.e, words not in the dictionary with the index as set via `unknown_word_index`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      document : list of str\n",
      " |          Input document\n",
      " |      unknown_word_index : int, optional\n",
      " |          Index to use for words not in the dictionary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of int\n",
      " |          Token ids for tokens in `document`, in the same order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [[\"a\", \"a\", \"b\"], [\"a\", \"c\"]]\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> dct.doc2idx([\"a\", \"a\", \"c\", \"not_in_dictionary\", \"c\"])\n",
      " |          [0, 0, 2, -1, 2]\n",
      " |  \n",
      " |  filter_extremes(self, no_below=5, no_above=0.5, keep_n=100000, keep_tokens=None)\n",
      " |      Filter out tokens in the dictionary by their frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      no_below : int, optional\n",
      " |          Keep tokens which are contained in at least `no_below` documents.\n",
      " |      no_above : float, optional\n",
      " |          Keep tokens which are contained in no more than `no_above` documents\n",
      " |          (fraction of total corpus size, not an absolute number).\n",
      " |      keep_n : int, optional\n",
      " |          Keep only the first `keep_n` most frequent tokens.\n",
      " |      keep_tokens : iterable of str\n",
      " |          Iterable of tokens that **must** stay in dictionary after filtering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This removes all tokens in the dictionary that are:\n",
      " |      \n",
      " |      #. Less frequent than `no_below` documents (absolute number, e.g. `5`) or \n",
      " |      \n",
      " |      #. More frequent than `no_above` documents (fraction of the total corpus size, e.g. `0.3`).\n",
      " |      #. After (1) and (2), keep only the first `keep_n` most frequent tokens (or keep all if `keep_n=None`).\n",
      " |      \n",
      " |      After the pruning, resulting gaps in word ids are shrunk.\n",
      " |      Due to this gap shrinking, **the same word may have a different word id before and after the call\n",
      " |      to this function!**\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [[\"máma\", \"mele\", \"maso\"], [\"ema\", \"má\", \"máma\"]]\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> len(dct)\n",
      " |          5\n",
      " |          >>> dct.filter_extremes(no_below=1, no_above=0.5, keep_n=1)\n",
      " |          >>> len(dct)\n",
      " |          1\n",
      " |  \n",
      " |  filter_n_most_frequent(self, remove_n)\n",
      " |      Filter out the 'remove_n' most frequent tokens that appear in the documents.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      remove_n : int\n",
      " |          Number of the most frequent tokens that will be removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [[\"máma\", \"mele\", \"maso\"], [\"ema\", \"má\", \"máma\"]]\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> len(dct)\n",
      " |          5\n",
      " |          >>> dct.filter_n_most_frequent(2)\n",
      " |          >>> len(dct)\n",
      " |          3\n",
      " |  \n",
      " |  filter_tokens(self, bad_ids=None, good_ids=None)\n",
      " |      Remove the selected `bad_ids` tokens from :class:`~gensim.corpora.dictionary.Dictionary`.\n",
      " |      \n",
      " |      Alternatively, keep selected `good_ids` in :class:`~gensim.corpora.dictionary.Dictionary` and remove the rest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bad_ids : iterable of int, optional\n",
      " |          Collection of word ids to be removed.\n",
      " |      good_ids : collection of int, optional\n",
      " |          Keep selected collection of word ids and remove the rest.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [[\"máma\", \"mele\", \"maso\"], [\"ema\", \"má\", \"máma\"]]\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> 'ema' in dct.token2id\n",
      " |          True\n",
      " |          >>> dct.filter_tokens(bad_ids=[dct.token2id['ema']])\n",
      " |          >>> 'ema' in dct.token2id\n",
      " |          False\n",
      " |          >>> len(dct)\n",
      " |          4\n",
      " |          >>> dct.filter_tokens(good_ids=[dct.token2id['maso']])\n",
      " |          >>> len(dct)\n",
      " |          1\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |  \n",
      " |  iterkeys = __iter__(self)\n",
      " |  \n",
      " |  itervalues(self)\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get all stored ids.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of int\n",
      " |          List of all token ids.\n",
      " |  \n",
      " |  merge_with(self, other)\n",
      " |      Merge another dictionary into this dictionary, mapping the same tokens to the same ids\n",
      " |      and new tokens to new ids.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The purpose is to merge two corpora created using two different dictionaries: `self` and `other`.\n",
      " |      `other` can be any id=>word mapping (a dict, a Dictionary object, ...).\n",
      " |      \n",
      " |      Return a transformation object which, when accessed as `result[doc_from_other_corpus]`, will convert documents\n",
      " |      from a corpus built using the `other` dictionary into a document using the new, merged dictionary.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : {dict, :class:`~gensim.corpora.dictionary.Dictionary`}\n",
      " |          Other dictionary.\n",
      " |      \n",
      " |      Return\n",
      " |      ------\n",
      " |      :class:`gensim.models.VocabTransform`\n",
      " |          Transformation object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus_1, corpus_2 = [[\"a\", \"b\", \"c\"]], [[\"a\", \"f\", \"f\"]]\n",
      " |          >>> dct_1, dct_2 = Dictionary(corpus_1), Dictionary(corpus_2)\n",
      " |          >>> dct_1.doc2bow(corpus_2[0])\n",
      " |          [(0, 1)]\n",
      " |          >>> transformer = dct_1.merge_with(dct_2)\n",
      " |          >>> dct_1.doc2bow(corpus_2[0])\n",
      " |          [(0, 1), (3, 2)]\n",
      " |  \n",
      " |  patch_with_special_tokens(self, special_token_dict)\n",
      " |      Patch token2id and id2token using a dictionary of special tokens.\n",
      " |      \n",
      " |      \n",
      " |      **Usecase:** when doing sequence modeling (e.g. named entity recognition), one may  want to specify\n",
      " |      special tokens that behave differently than others.\n",
      " |      One example is the \"unknown\" token, and another is the padding token.\n",
      " |      It is usual to set the padding token to have index `0`, and patching the dictionary with `{'<PAD>': 0}`\n",
      " |      would be one way to specify this.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      special_token_dict : dict of (str, int)\n",
      " |          dict containing the special tokens as keys and their wanted indices as values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [[\"máma\", \"mele\", \"maso\"], [\"ema\", \"má\", \"máma\"]]\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>>\n",
      " |          >>> special_tokens = {'pad': 0, 'space': 1}\n",
      " |          >>> print(dct.token2id)\n",
      " |          {'maso': 0, 'mele': 1, 'máma': 2, 'ema': 3, 'má': 4}\n",
      " |          >>>\n",
      " |          >>> dct.patch_with_special_tokens(special_tokens)\n",
      " |          >>> print(dct.token2id)\n",
      " |          {'maso': 6, 'mele': 7, 'máma': 2, 'ema': 3, 'má': 4, 'pad': 0, 'space': 1}\n",
      " |  \n",
      " |  save_as_text(self, fname, sort_by_word=True)\n",
      " |      Save :class:`~gensim.corpora.dictionary.Dictionary` to a text file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to output file.\n",
      " |      sort_by_word : bool, optional\n",
      " |          Sort words in lexicographical order before writing them out?\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Format::\n",
      " |      \n",
      " |          num_docs\n",
      " |          id_1[TAB]word_1[TAB]document_frequency_1[NEWLINE]\n",
      " |          id_2[TAB]word_2[TAB]document_frequency_2[NEWLINE]\n",
      " |          ....\n",
      " |          id_k[TAB]word_k[TAB]document_frequency_k[NEWLINE]\n",
      " |      \n",
      " |      This text format is great for corpus inspection and debugging. As plaintext, it's also easily portable\n",
      " |      to other tools and frameworks. For better performance and to store the entire object state,\n",
      " |      including collected corpus statistics, use :meth:`~gensim.corpora.dictionary.Dictionary.save` and\n",
      " |      :meth:`~gensim.corpora.dictionary.Dictionary.load` instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.corpora.dictionary.Dictionary.load_from_text`\n",
      " |          Load :class:`~gensim.corpora.dictionary.Dictionary` from text file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>> from gensim.test.utils import get_tmpfile\n",
      " |          >>>\n",
      " |          >>> tmp_fname = get_tmpfile(\"dictionary\")\n",
      " |          >>> corpus = [[\"máma\", \"mele\", \"maso\"], [\"ema\", \"má\", \"máma\"]]\n",
      " |          >>>\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> dct.save_as_text(tmp_fname)\n",
      " |          >>>\n",
      " |          >>> loaded_dct = Dictionary.load_from_text(tmp_fname)\n",
      " |          >>> assert dct.token2id == loaded_dct.token2id\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  from_corpus(corpus, id2word=None)\n",
      " |      Create :class:`~gensim.corpora.dictionary.Dictionary` from an existing corpus.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of iterable of (int, number)\n",
      " |          Corpus in BoW format.\n",
      " |      id2word : dict of (int, object)\n",
      " |          Mapping id -> word. If None, the mapping `id2word[word_id] = str(word_id)` will be used.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This can be useful if you only have a term-document BOW matrix (represented by `corpus`), but not the original\n",
      " |      text corpus. This method will scan the term-document count matrix for all word ids that appear in it,\n",
      " |      then construct :class:`~gensim.corpora.dictionary.Dictionary` which maps each `word_id -> id2word[word_id]`.\n",
      " |      `id2word` is an optional dictionary that maps the `word_id` to a token.\n",
      " |      In case `id2word` isn't specified the mapping `id2word[word_id] = str(word_id)` will be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~gensim.corpora.dictionary.Dictionary`\n",
      " |          Inferred dictionary from corpus.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>>\n",
      " |          >>> corpus = [[(1, 1.0)], [], [(0, 5.0), (2, 1.0)], []]\n",
      " |          >>> dct = Dictionary.from_corpus(corpus)\n",
      " |          >>> len(dct)\n",
      " |          3\n",
      " |  \n",
      " |  from_documents(documents)\n",
      " |      Create :class:`~gensim.corpora.dictionary.Dictionary` from `documents`.\n",
      " |      \n",
      " |      Equivalent to `Dictionary(documents=documents)`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      documents : iterable of iterable of str\n",
      " |          Input corpus.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~gensim.corpora.dictionary.Dictionary`\n",
      " |          Dictionary initialized from `documents`.\n",
      " |  \n",
      " |  load_from_text(fname)\n",
      " |      Load a previously stored :class:`~gensim.corpora.dictionary.Dictionary` from a text file.\n",
      " |      \n",
      " |      Mirror function to :meth:`~gensim.corpora.dictionary.Dictionary.save_as_text`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname: str\n",
      " |          Path to a file produced by :meth:`~gensim.corpora.dictionary.Dictionary.save_as_text`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.corpora.dictionary.Dictionary.save_as_text`\n",
      " |          Save :class:`~gensim.corpora.dictionary.Dictionary` to text file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import Dictionary\n",
      " |          >>> from gensim.test.utils import get_tmpfile\n",
      " |          >>>\n",
      " |          >>> tmp_fname = get_tmpfile(\"dictionary\")\n",
      " |          >>> corpus = [[\"máma\", \"mele\", \"maso\"], [\"ema\", \"má\", \"máma\"]]\n",
      " |          >>>\n",
      " |          >>> dct = Dictionary(corpus)\n",
      " |          >>> dct.save_as_text(tmp_fname)\n",
      " |          >>>\n",
      " |          >>> loaded_dct = Dictionary.load_from_text(tmp_fname)\n",
      " |          >>> assert dct.token2id == loaded_dct.token2id\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  save(self, fname_or_handle, separately=None, sep_limit=10485760, ignore=frozenset(), pickle_protocol=2)\n",
      " |      Save the object to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname_or_handle : str or file-like\n",
      " |          Path to output file or already opened file-like object. If the object is a file handle,\n",
      " |          no special array handling will be performed, all attributes will be saved to the same file.\n",
      " |      separately : list of str or None, optional\n",
      " |          If None, automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This prevent memory errors for large objects, and also allows\n",
      " |          `memory-mapping <https://en.wikipedia.org/wiki/Mmap>`_ the large arrays for efficient\n",
      " |          loading and sharing the large arrays in RAM between multiple processes.\n",
      " |      \n",
      " |          If list of str: store these attributes into separate files. The automated size check\n",
      " |          is not performed in this case.\n",
      " |      sep_limit : int, optional\n",
      " |          Don't store arrays smaller than this separately. In bytes.\n",
      " |      ignore : frozenset of str, optional\n",
      " |          Attributes that shouldn't be stored at all.\n",
      " |      pickle_protocol : int, optional\n",
      " |          Protocol number for pickle.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.load`\n",
      " |          Load object from file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  load(fname, mmap=None) from abc.ABCMeta\n",
      " |      Load an object previously saved using :meth:`~gensim.utils.SaveLoad.save` from a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file that contains needed object.\n",
      " |      mmap : str, optional\n",
      " |          Memory-map option.  If the object was saved with large arrays stored separately, you can load these arrays\n",
      " |          via mmap (shared memory) using `mmap='r'.\n",
      " |          If the file being loaded is compressed (either '.gz' or '.bz2'), then `mmap=None` **must be** set.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.save`\n",
      " |          Save object to file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object\n",
      " |          Object loaded from `fname`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          When called on an object instance instead of class (this is a class method).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      " |  \n",
      " |  items(self)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  values(self)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __reversed__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Collection:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TfidfModel in module gensim.models.tfidfmodel:\n",
      "\n",
      "class TfidfModel(gensim.interfaces.TransformationABC)\n",
      " |  Objects of this class realize the transformation between word-document co-occurrence matrix (int)\n",
      " |  into a locally/globally weighted TF-IDF matrix (positive floats).\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> import gensim.downloader as api\n",
      " |      >>> from gensim.models import TfidfModel\n",
      " |      >>> from gensim.corpora import Dictionary\n",
      " |      >>>\n",
      " |      >>> dataset = api.load(\"text8\")\n",
      " |      >>> dct = Dictionary(dataset)  # fit dictionary\n",
      " |      >>> corpus = [dct.doc2bow(line) for line in dataset]  # convert corpus to BoW format\n",
      " |      >>>\n",
      " |      >>> model = TfidfModel(corpus)  # fit model\n",
      " |      >>> vector = model[corpus[0]]  # apply model to the first corpus document\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TfidfModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, bow, eps=1e-12)\n",
      " |      Get the tf-idf representation of an input vector and/or corpus.\n",
      " |      \n",
      " |      bow : {list of (int, int), iterable of iterable of (int, int)}\n",
      " |          Input document in the `sparse Gensim bag-of-words format\n",
      " |          <https://radimrehurek.com/gensim/intro.html#core-concepts>`_,\n",
      " |          or a streamed corpus of such documents.\n",
      " |      eps : float\n",
      " |          Threshold value, will remove all position that have tfidf-value less than `eps`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      vector : list of (int, float)\n",
      " |          TfIdf vector, if `bow` is a single document\n",
      " |      :class:`~gensim.interfaces.TransformedCorpus`\n",
      " |          TfIdf corpus, if `bow` is a corpus.\n",
      " |  \n",
      " |  __init__(self, corpus=None, id2word=None, dictionary=None, wlocal=<function identity at 0x7f7f7c3ed1e0>, wglobal=<function df2idf at 0x7f7f793a7268>, normalize=True, smartirs=None, pivot=None, slope=0.25)\n",
      " |      Compute TF-IDF by multiplying a local component (term frequency) with a global component\n",
      " |      (inverse document frequency), and normalizing the resulting documents to unit length.\n",
      " |      Formula for non-normalized weight of term :math:`i` in document :math:`j` in a corpus of :math:`D` documents\n",
      " |      \n",
      " |      .. math:: weight_{i,j} = frequency_{i,j} * log_2 \\frac{D}{document\\_freq_{i}}\n",
      " |      \n",
      " |      or, more generally\n",
      " |      \n",
      " |      .. math:: weight_{i,j} = wlocal(frequency_{i,j}) * wglobal(document\\_freq_{i}, D)\n",
      " |      \n",
      " |      so you can plug in your own custom :math:`wlocal` and :math:`wglobal` functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of iterable of (int, int), optional\n",
      " |          Input corpus\n",
      " |      id2word : {dict, :class:`~gensim.corpora.Dictionary`}, optional\n",
      " |          Mapping token - id, that was used for converting input data to bag of words format.\n",
      " |      dictionary : :class:`~gensim.corpora.Dictionary`\n",
      " |          If `dictionary` is specified, it must be a `corpora.Dictionary` object and it will be used.\n",
      " |          to directly construct the inverse document frequency mapping (then `corpus`, if specified, is ignored).\n",
      " |      wlocals : callable, optional\n",
      " |          Function for local weighting, default for `wlocal` is :func:`~gensim.utils.identity`\n",
      " |          (other options: :func:`numpy.sqrt`, `lambda tf: 0.5 + (0.5 * tf / tf.max())`, etc.).\n",
      " |      wglobal : callable, optional\n",
      " |          Function for global weighting, default is :func:`~gensim.models.tfidfmodel.df2idf`.\n",
      " |      normalize : {bool, callable}, optional\n",
      " |          Normalize document vectors to unit euclidean length? You can also inject your own function into `normalize`.\n",
      " |      smartirs : str, optional\n",
      " |          SMART (System for the Mechanical Analysis and Retrieval of Text) Information Retrieval System,\n",
      " |          a mnemonic scheme for denoting tf-idf weighting variants in the vector space model.\n",
      " |          The mnemonic for representing a combination of weights takes the form XYZ,\n",
      " |          for example 'ntc', 'bpn' and so on, where the letters represents the term weighting of the document vector.\n",
      " |      \n",
      " |          Term frequency weighing:\n",
      " |              * `b` - binary,\n",
      " |              * `t` or `n` - raw,\n",
      " |              * `a` - augmented,\n",
      " |              * `l` - logarithm,\n",
      " |              * `d` - double logarithm,\n",
      " |              * `L` - log average.\n",
      " |      \n",
      " |          Document frequency weighting:\n",
      " |              * `x` or `n` - none,\n",
      " |              * `f` - idf,\n",
      " |              * `t` - zero-corrected idf,\n",
      " |              * `p` - probabilistic idf.\n",
      " |      \n",
      " |          Document normalization:\n",
      " |              * `x` or `n` - none,\n",
      " |              * `c` - cosine,\n",
      " |              * `u` - pivoted unique,\n",
      " |              * `b` - pivoted character length.\n",
      " |      \n",
      " |          Default is 'nfc'.\n",
      " |          For more information visit `SMART Information Retrieval System\n",
      " |          <https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System>`_.\n",
      " |      pivot : float or None, optional\n",
      " |          In information retrieval, TF-IDF is biased against long documents [1]_. Pivoted document length\n",
      " |          normalization solves this problem by changing the norm of a document to `slope * old_norm + (1.0 -\n",
      " |          slope) * pivot`.\n",
      " |      \n",
      " |          You can either set the `pivot` by hand, or you can let Gensim figure it out automatically with the following\n",
      " |          two steps:\n",
      " |      \n",
      " |              * Set either the `u` or `b` document normalization in the `smartirs` parameter.\n",
      " |              * Set either the `corpus` or `dictionary` parameter. The `pivot` will be automatically determined from\n",
      " |                the properties of the `corpus` or `dictionary`.\n",
      " |      \n",
      " |          If `pivot` is None and you don't follow steps 1 and 2, then pivoted document length normalization will be\n",
      " |          disabled. Default is None.\n",
      " |      \n",
      " |          See also the blog post at https://rare-technologies.com/pivoted-document-length-normalisation/.\n",
      " |      slope : float, optional\n",
      " |          In information retrieval, TF-IDF is biased against long documents [1]_. Pivoted document length\n",
      " |          normalization solves this problem by changing the norm of a document to `slope * old_norm + (1.0 -\n",
      " |          slope) * pivot`.\n",
      " |      \n",
      " |          Setting the `slope` to 0.0 uses only the `pivot` as the norm, and setting the `slope` to 1.0 effectively\n",
      " |          disables pivoted document length normalization. Singhal [2]_ suggests setting the `slope` between 0.2 and\n",
      " |          0.3 for best results. Default is 0.25.\n",
      " |      \n",
      " |          See also the blog post at https://rare-technologies.com/pivoted-document-length-normalisation/.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ~gensim.sklearn_api.tfidf.TfIdfTransformer : Class that also uses the SMART scheme.\n",
      " |      resolve_weights : Function that also uses the SMART scheme.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Singhal, A., Buckley, C., & Mitra, M. (1996). `Pivoted Document Length\n",
      " |         Normalization <http://singhal.info/pivoted-dln.pdf>`_. *SIGIR Forum*, 51, 176–184.\n",
      " |      .. [2] Singhal, A. (2001). `Modern information retrieval: A brief overview <http://singhal.info/ieee2001.pdf>`_.\n",
      " |         *IEEE Data Eng. Bull.*, 24(4), 35–43.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  initialize(self, corpus)\n",
      " |      Compute inverse document weights, which will be used to modify term frequencies for documents.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of iterable of (int, int)\n",
      " |          Input corpus.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(*args, **kwargs) from builtins.type\n",
      " |      Load a previously saved TfidfModel class. Handles backwards compatibility from\n",
      " |      older TfidfModel versions which did not use pivoted document normalization.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  save(self, fname_or_handle, separately=None, sep_limit=10485760, ignore=frozenset(), pickle_protocol=2)\n",
      " |      Save the object to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname_or_handle : str or file-like\n",
      " |          Path to output file or already opened file-like object. If the object is a file handle,\n",
      " |          no special array handling will be performed, all attributes will be saved to the same file.\n",
      " |      separately : list of str or None, optional\n",
      " |          If None, automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This prevent memory errors for large objects, and also allows\n",
      " |          `memory-mapping <https://en.wikipedia.org/wiki/Mmap>`_ the large arrays for efficient\n",
      " |          loading and sharing the large arrays in RAM between multiple processes.\n",
      " |      \n",
      " |          If list of str: store these attributes into separate files. The automated size check\n",
      " |          is not performed in this case.\n",
      " |      sep_limit : int, optional\n",
      " |          Don't store arrays smaller than this separately. In bytes.\n",
      " |      ignore : frozenset of str, optional\n",
      " |          Attributes that shouldn't be stored at all.\n",
      " |      pickle_protocol : int, optional\n",
      " |          Protocol number for pickle.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.load`\n",
      " |          Load object from file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TfidfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LsiModel in module gensim.models.lsimodel:\n",
      "\n",
      "class LsiModel(gensim.interfaces.TransformationABC, gensim.models.basemodel.BaseTopicModel)\n",
      " |  Model for `Latent Semantic Indexing\n",
      " |  <https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing>`_.\n",
      " |  \n",
      " |  The decomposition algorithm is described in `\"Fast and Faster: A Comparison of Two Streamed\n",
      " |  Matrix Decomposition Algorithms\" <https://nlp.fi.muni.cz/~xrehurek/nips/rehurek_nips.pdf>`_.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  * :attr:`gensim.models.lsimodel.LsiModel.projection.u` - left singular vectors,\n",
      " |  * :attr:`gensim.models.lsimodel.LsiModel.projection.s` - singular values,\n",
      " |  * ``model[training_corpus]`` - right singular vectors (can be reconstructed if needed).\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  `FAQ about LSI matrices\n",
      " |  <https://github.com/piskvorky/gensim/wiki/Recipes-&-FAQ#q4-how-do-you-output-the-u-s-vt-matrices-of-lsi>`_.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
      " |      >>> from gensim.models import LsiModel\n",
      " |      >>>\n",
      " |      >>> model = LsiModel(common_corpus[:3], id2word=common_dictionary)  # train model\n",
      " |      >>> vector = model[common_corpus[4]]  # apply model to BoW document\n",
      " |      >>> model.add_documents(common_corpus[4:])  # update model with new documents\n",
      " |      >>> tmp_fname = get_tmpfile(\"lsi.model\")\n",
      " |      >>> model.save(tmp_fname)  # save model\n",
      " |      >>> loaded_model = LsiModel.load(tmp_fname)  # load model\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LsiModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      gensim.models.basemodel.BaseTopicModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, bow, scaled=False, chunksize=512)\n",
      " |      Get the latent representation for `bow`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bow : {list of (int, int), iterable of list of (int, int)}\n",
      " |          Document or corpus in BoW representation.\n",
      " |      scaled : bool, optional\n",
      " |          If True - topics will be scaled by the inverse of singular values.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each applying chunk.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Latent representation of topics in BoW format for document **OR**\n",
      " |      :class:`gensim.matutils.Dense2Corpus`\n",
      " |          Latent representation of corpus in BoW format if `bow` is corpus.\n",
      " |  \n",
      " |  __init__(self, corpus=None, num_topics=200, id2word=None, chunksize=20000, decay=1.0, distributed=False, onepass=True, power_iters=2, extra_samples=100, dtype=<class 'numpy.float64'>)\n",
      " |      Construct an `LsiModel` object.\n",
      " |      \n",
      " |      Either `corpus` or `id2word` must be supplied in order to train the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`).\n",
      " |      num_topics : int, optional\n",
      " |          Number of requested factors (latent dimensions)\n",
      " |      id2word : dict of {int: str}, optional\n",
      " |          ID to word mapping, optional.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      decay : float, optional\n",
      " |          Weight of existing observations relatively to new ones.\n",
      " |      distributed : bool, optional\n",
      " |          If True - distributed mode (parallel execution on several machines) will be used.\n",
      " |      onepass : bool, optional\n",
      " |          Whether the one-pass algorithm should be used for training.\n",
      " |          Pass `False` to force a multi-pass stochastic algorithm.\n",
      " |      power_iters: int, optional\n",
      " |          Number of power iteration steps to be used.\n",
      " |          Increasing the number of power iterations improves accuracy, but lowers performance\n",
      " |      extra_samples : int, optional\n",
      " |          Extra samples to be used besides the rank `k`. Can improve accuracy.\n",
      " |      dtype : type, optional\n",
      " |          Enforces a type for elements of the decomposed matrix.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get a human readable representation of model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          A human readable string of the current objects parameters.\n",
      " |  \n",
      " |  add_documents(self, corpus, chunksize=None, decay=None)\n",
      " |      Update model with new `corpus`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, num_documents).\n",
      " |      chunksize : int, optional\n",
      " |          Number of documents to be used in each training chunk, will use `self.chunksize` if not specified.\n",
      " |      decay : float, optional\n",
      " |          Weight of existing observations relatively to new ones,  will use `self.decay` if not specified.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Training proceeds in chunks of `chunksize` documents at a time. The size of `chunksize` is a tradeoff\n",
      " |      between increased speed (bigger `chunksize`) vs. lower memory footprint (smaller `chunksize`).\n",
      " |      If the distributed mode is on, each chunk is sent to a different worker/computer.\n",
      " |  \n",
      " |  get_topics(self)\n",
      " |      Get the topic vectors.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The number of topics can actually be smaller than `self.num_topics`, if there were not enough factors\n",
      " |      in the matrix (real rank of input matrix smaller than `self.num_topics`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray\n",
      " |          The term topic matrix with shape (`num_topics`, `vocabulary_size`)\n",
      " |  \n",
      " |  print_debug(self, num_topics=5, num_words=10)\n",
      " |      Print (to log) the most salient words of the first `num_topics` topics.\n",
      " |      \n",
      " |      Unlike :meth:`~gensim.models.lsimodel.LsiModel.print_topics`, this looks for words that are significant for\n",
      " |      a particular topic *and* not for others. This *should* result in a\n",
      " |      more human-interpretable description of topics.\n",
      " |      \n",
      " |      Alias for :func:`~gensim.models.lsimodel.print_debug`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |  \n",
      " |  save(self, fname, *args, **kwargs)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Large internal arrays may be stored into separate files, with `fname` as prefix.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      Do not save as a compressed file if you intend to load the file back with `mmap`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to output file.\n",
      " |      *args\n",
      " |          Variable length argument list, see :meth:`gensim.utils.SaveLoad.save`.\n",
      " |      **kwargs\n",
      " |          Arbitrary keyword arguments, see :meth:`gensim.utils.SaveLoad.save`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.lsimodel.LsiModel.load`\n",
      " |  \n",
      " |  show_topic(self, topicno, topn=10)\n",
      " |      Get the words that define a topic along with their contribution.\n",
      " |      \n",
      " |      This is actually the left singular vector of the specified topic.\n",
      " |      \n",
      " |      The most important words in defining the topic (greatest absolute value) are included\n",
      " |      in the output, along with their contribution to the topic.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          The topics id number.\n",
      " |      topn : int\n",
      " |          Number of words to be included to the result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (str, float)\n",
      " |          Topic representation in BoW format.\n",
      " |  \n",
      " |  show_topics(self, num_topics=-1, num_words=10, log=False, formatted=True)\n",
      " |      Get the most significant topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      log : bool, optional\n",
      " |          If True - log topics with logger.\n",
      " |      formatted : bool, optional\n",
      " |          If True - each topic represented as string, otherwise - in BoW format.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, str)\n",
      " |          If `formatted=True`, return sequence with (topic_id, string representation of topics) **OR**\n",
      " |      list of (int, list of (str, float))\n",
      " |          Otherwise, return sequence with (topic_id, [(word, value), ... ]).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(fname, *args, **kwargs) from builtins.type\n",
      " |      Load a previously saved object using :meth:`~gensim.models.lsimodel.LsiModel.save` from file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Large arrays can be memmap'ed back as read-only (shared memory) by setting the `mmap='r'` parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file that contains LsiModel.\n",
      " |      *args\n",
      " |          Variable length argument list, see :meth:`gensim.utils.SaveLoad.load`.\n",
      " |      **kwargs\n",
      " |          Arbitrary keyword arguments, see :meth:`gensim.utils.SaveLoad.load`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.lsimodel.LsiModel.save`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~gensim.models.lsimodel.LsiModel`\n",
      " |          Loaded instance.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IOError\n",
      " |          When methods are called on instance (should be called from class).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.basemodel.BaseTopicModel:\n",
      " |  \n",
      " |  print_topic(self, topicno, topn=10)\n",
      " |      Get a single topic as a formatted string.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          Topic id.\n",
      " |      topn : int\n",
      " |          Number of words from topic that will be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          String representation of topic, like '-0.340 * \"category\" + 0.298 * \"$M$\" + 0.183 * \"algebra\" + ... '.\n",
      " |  \n",
      " |  print_topics(self, num_topics=20, num_words=10)\n",
      " |      Get the most significant topics (alias for `show_topics()` method).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, list of (str, float))\n",
      " |          Sequence with (topic_id, [(word, value), ... ]).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LsiModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_df = pd.read_csv(os.path.join(dataDir, 'question_info_1111.csv'),\n",
    "                       usecols= ['question_id', 'title_SW', 'title_W'],\n",
    "                       index_col='question_id',\n",
    "                       sep='\\t',\n",
    "                       #nrows= 10000\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_SW</th>\n",
       "      <th>title_W</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q2234111670</th>\n",
       "      <td>SW211,SW204,SW1715,SW69,SW2033,SW138,SW57,SW13...</td>\n",
       "      <td>W22414,W963,W10458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q760329790</th>\n",
       "      <td>SW69,SW2033,SW138,SW2616,SW2668,SW36,SW2594,SW...</td>\n",
       "      <td>W12677,W16829,W15201,W6419,W101839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q741313548</th>\n",
       "      <td>SW153,SW662,SW1218,SW853,SW325,SW1056,SW467,SW...</td>\n",
       "      <td>W700,W2781,W3280,W81215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3481466230</th>\n",
       "      <td>SW22,SW179,SW57,SW451,SW594,SW118,SW882,SW655,...</td>\n",
       "      <td>W3312,W1823,W1505,W638,W166,W461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3966197028</th>\n",
       "      <td>SW1622,SW223,SW1218,SW853,SW390,SW220,SW753,SW...</td>\n",
       "      <td>W700,W895,W2253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title_SW  \\\n",
       "question_id                                                      \n",
       "Q2234111670  SW211,SW204,SW1715,SW69,SW2033,SW138,SW57,SW13...   \n",
       "Q760329790   SW69,SW2033,SW138,SW2616,SW2668,SW36,SW2594,SW...   \n",
       "Q741313548   SW153,SW662,SW1218,SW853,SW325,SW1056,SW467,SW...   \n",
       "Q3481466230  SW22,SW179,SW57,SW451,SW594,SW118,SW882,SW655,...   \n",
       "Q3966197028  SW1622,SW223,SW1218,SW853,SW390,SW220,SW753,SW...   \n",
       "\n",
       "                                        title_W  \n",
       "question_id                                      \n",
       "Q2234111670                  W22414,W963,W10458  \n",
       "Q760329790   W12677,W16829,W15201,W6419,W101839  \n",
       "Q741313548              W700,W2781,W3280,W81215  \n",
       "Q3481466230    W3312,W1823,W1505,W638,W166,W461  \n",
       "Q3966197028                     W700,W895,W2253  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpuse = map(lambda s: s.split(','), quest_df['title_SW'].tolist())\n",
    "\n",
    "dictionary = Dictionary(corpuse, prune_at=DICTLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below= 2, no_above= 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF_corpus():\n",
    "    def __init__(self, corpus, dictionary):\n",
    "        self.corpus = corpus\n",
    "        self.dictionary = dictionary\n",
    "        self.tfidf = TfidfModel(map(lambda sentence: dictionary.doc2bow(sentence.split(',')), corpus))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i, line in enumerate(self.corpus):\n",
    "            bow = self.tfidf[self.dictionary.doc2bow(line.split(','))]\n",
    "            # print(i)\n",
    "            if len(bow) > 0:\n",
    "                yield bow\n",
    "            else:\n",
    "                print(\"Zero length comment encountered: %s\" %(line, ))\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W40734\n",
      "Zero length comment encountered: W128427,W129744\n",
      "Zero length comment encountered: W46232\n",
      "Zero length comment encountered: W40914\n",
      "Zero length comment encountered: W130472\n",
      "Zero length comment encountered: W26437\n",
      "Zero length comment encountered: W101978\n",
      "Zero length comment encountered: W178077\n",
      "Zero length comment encountered: W70144\n",
      "Zero length comment encountered: W558669,W105409,W189216,W86619\n",
      "Zero length comment encountered: W36493\n",
      "Zero length comment encountered: W62262\n",
      "Zero length comment encountered: W141053\n",
      "Zero length comment encountered: W107278\n",
      "Zero length comment encountered: W125270,W13126\n",
      "Zero length comment encountered: W169052,W694778\n",
      "Zero length comment encountered: W82428\n",
      "Zero length comment encountered: W112850\n",
      "Zero length comment encountered: W37082\n",
      "Zero length comment encountered: W82132,W94025\n",
      "Zero length comment encountered: W188036,W18903\n",
      "Zero length comment encountered: W300722,W43302\n",
      "Zero length comment encountered: W72347\n",
      "Zero length comment encountered: W70691\n",
      "Zero length comment encountered: W144854,W61838\n",
      "Zero length comment encountered: W112641\n",
      "Zero length comment encountered: W29206,W72114,W57383\n",
      "Zero length comment encountered: W38895,W16362\n",
      "Zero length comment encountered: W21390,W125843\n",
      "Zero length comment encountered: W175869,W50957,W107674\n",
      "Zero length comment encountered: W44229\n",
      "Zero length comment encountered: W99198\n",
      "Zero length comment encountered: W9600,W24059,W14693\n",
      "Zero length comment encountered: W119183\n",
      "Zero length comment encountered: W39619\n",
      "Zero length comment encountered: W90275,W41793,W12286\n",
      "Zero length comment encountered: W132687,W17957,W80809\n",
      "Zero length comment encountered: W39204\n",
      "Zero length comment encountered: W104927\n",
      "Zero length comment encountered: W235913\n",
      "Zero length comment encountered: W56897,W115845\n",
      "Zero length comment encountered: W16007\n",
      "Zero length comment encountered: W12988,W111217\n",
      "Zero length comment encountered: W61957,W39279,W96178\n",
      "Zero length comment encountered: W130904\n",
      "Zero length comment encountered: W126726,W42849,W20123\n",
      "Zero length comment encountered: W61557,W201570\n",
      "Zero length comment encountered: W54554\n",
      "Zero length comment encountered: W208271,W40926\n",
      "Zero length comment encountered: W154340,W69897\n",
      "Zero length comment encountered: W43514\n",
      "Zero length comment encountered: W100788,W18372\n",
      "Zero length comment encountered: W57711\n",
      "Zero length comment encountered: W449559,W24606,W24559\n",
      "Zero length comment encountered: W124581,W95398,W51056\n",
      "Zero length comment encountered: W45153\n",
      "Zero length comment encountered: W57667\n",
      "Zero length comment encountered: W29866,W7355,W7355\n",
      "Zero length comment encountered: W369711\n",
      "Zero length comment encountered: W74903,W18523,W26045\n",
      "Zero length comment encountered: W156440,W19840\n",
      "Zero length comment encountered: W92930,W436254,W160016\n",
      "Zero length comment encountered: W530749,W51511\n",
      "Zero length comment encountered: W108854\n",
      "Zero length comment encountered: W774694,W62688\n",
      "Zero length comment encountered: W74729,W45486,W20123\n",
      "Zero length comment encountered: W29030,W176752\n",
      "Zero length comment encountered: W24559\n",
      "Zero length comment encountered: W87297\n",
      "Zero length comment encountered: W95301\n",
      "Zero length comment encountered: W174956\n",
      "Zero length comment encountered: W21075\n",
      "Zero length comment encountered: W35999\n",
      "Zero length comment encountered: W39017\n",
      "Zero length comment encountered: W85585\n",
      "Zero length comment encountered: W41838\n",
      "Zero length comment encountered: W220033,W21911,W152291\n",
      "Zero length comment encountered: W130269,W88961,W424765,W77090\n",
      "Zero length comment encountered: W57959,W27871\n",
      "Zero length comment encountered: W135288,W124864\n",
      "Zero length comment encountered: W102781\n",
      "Zero length comment encountered: W146451\n",
      "Zero length comment encountered: W162752\n",
      "Zero length comment encountered: W60515,W64546\n",
      "Zero length comment encountered: W11603,W79145\n",
      "Zero length comment encountered: W75627\n",
      "Zero length comment encountered: W101379\n",
      "Zero length comment encountered: W62581\n",
      "Zero length comment encountered: W47873\n",
      "Zero length comment encountered: W508108\n",
      "Zero length comment encountered: W38025\n",
      "Zero length comment encountered: W23028,W29056\n",
      "Zero length comment encountered: W34803\n",
      "Zero length comment encountered: W92772,W92772\n",
      "Zero length comment encountered: W125839\n",
      "Zero length comment encountered: W1091483\n",
      "Zero length comment encountered: W14275\n",
      "Zero length comment encountered: W77557,W102006\n",
      "Zero length comment encountered: W23569\n",
      "Zero length comment encountered: W22017,W11475\n",
      "Zero length comment encountered: W306653\n",
      "Zero length comment encountered: W138421,W134062\n",
      "Zero length comment encountered: W38832,W38832\n",
      "Zero length comment encountered: W763887\n",
      "Zero length comment encountered: W26081\n",
      "Zero length comment encountered: W234328\n",
      "Zero length comment encountered: W50520,W38212,W37522\n",
      "Zero length comment encountered: W162970,W25579,W88211\n",
      "Zero length comment encountered: W99608\n",
      "Zero length comment encountered: W67469,W58166\n",
      "Zero length comment encountered: W164184\n",
      "Zero length comment encountered: W195841,W29715,W14448\n",
      "Zero length comment encountered: W180021\n",
      "Zero length comment encountered: W56196,W29187,W27961\n",
      "Zero length comment encountered: W118876,W25035,W118876\n",
      "Zero length comment encountered: W220713,W408786,W99791,W233653,W160432,W345372,W251874,W160432,W226389,W296314,W99791,W263761,W160432,W237940,W160432,W220713,W99791,W241648,W160432,W136292\n",
      "Zero length comment encountered: W80084,W44131\n",
      "Zero length comment encountered: W21077\n",
      "Zero length comment encountered: W21092\n",
      "Zero length comment encountered: W50145\n",
      "Zero length comment encountered: W129545,W510777,W510777\n",
      "Zero length comment encountered: W113416,W159688\n",
      "Zero length comment encountered: W91261\n",
      "Zero length comment encountered: W244626\n",
      "Zero length comment encountered: W11274\n",
      "Zero length comment encountered: W137334,W31324\n",
      "Zero length comment encountered: W11937\n",
      "Zero length comment encountered: W40093\n",
      "Zero length comment encountered: W203722\n",
      "Zero length comment encountered: W96473\n",
      "Zero length comment encountered: W1435078,W48108\n",
      "Zero length comment encountered: W27097,W16890\n",
      "Zero length comment encountered: W56459\n",
      "Zero length comment encountered: W132697,W123412\n",
      "Zero length comment encountered: W37109,W119561\n",
      "Zero length comment encountered: W115691,W40133\n",
      "Zero length comment encountered: W19171,W151263\n",
      "Zero length comment encountered: W33795,W69762\n",
      "Zero length comment encountered: W1174249,W215782\n",
      "Zero length comment encountered: W89244\n",
      "Zero length comment encountered: W36149,W99884\n",
      "Zero length comment encountered: W22150,W7209,W42903\n",
      "Zero length comment encountered: W203962,W62538\n",
      "Zero length comment encountered: W21869,W88955\n",
      "Zero length comment encountered: W130269\n",
      "Zero length comment encountered: W89886\n",
      "Zero length comment encountered: W71241,W321271\n",
      "Zero length comment encountered: W27917\n",
      "Zero length comment encountered: W36020,W17629\n",
      "Zero length comment encountered: W125092\n",
      "Zero length comment encountered: W42797\n",
      "Zero length comment encountered: W301828,W301828\n",
      "Zero length comment encountered: W24731\n",
      "Zero length comment encountered: W20525\n",
      "Zero length comment encountered: W123948,W344300\n",
      "Zero length comment encountered: W94379,W616110\n",
      "Zero length comment encountered: W331525,W112025\n",
      "Zero length comment encountered: W453235\n",
      "Zero length comment encountered: W107915\n",
      "Zero length comment encountered: W20746,W22466\n",
      "Zero length comment encountered: W436160,W468144\n",
      "Zero length comment encountered: W36974\n",
      "Zero length comment encountered: W177648\n",
      "Zero length comment encountered: W462339\n",
      "Zero length comment encountered: W112665,W126336,W15326,W126336,W112665,W15326\n",
      "Zero length comment encountered: W13977\n",
      "Zero length comment encountered: W216746\n",
      "Zero length comment encountered: W275385,W161679\n",
      "Zero length comment encountered: W44894,W145091\n",
      "Zero length comment encountered: W59264\n",
      "Zero length comment encountered: W36149,W18317\n",
      "Zero length comment encountered: W115856\n",
      "Zero length comment encountered: W47949,W126279\n",
      "Zero length comment encountered: W36639\n",
      "Zero length comment encountered: W87754,W25907\n",
      "Zero length comment encountered: W128244,W87273\n",
      "Zero length comment encountered: W23591\n",
      "Zero length comment encountered: W148251,W94510\n",
      "Zero length comment encountered: W70577,W56641\n",
      "Zero length comment encountered: W109435,W12880\n",
      "Zero length comment encountered: W55258\n",
      "Zero length comment encountered: W50250\n",
      "Zero length comment encountered: W8687,W63922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W19738,W47047,W106860\n",
      "Zero length comment encountered: W75497\n",
      "Zero length comment encountered: W132869,W81809,W195300\n",
      "Zero length comment encountered: W29298\n",
      "Zero length comment encountered: W77079,W18303,W17725\n",
      "Zero length comment encountered: W37465\n",
      "Zero length comment encountered: W201136,W51453\n",
      "Zero length comment encountered: W12908,W19975\n",
      "Zero length comment encountered: W65444\n",
      "Zero length comment encountered: W357499,W47678\n",
      "Zero length comment encountered: W253194,W50124,W176756\n",
      "Zero length comment encountered: W50145\n",
      "Zero length comment encountered: W25097,W167165\n",
      "Zero length comment encountered: W365364,W545695\n",
      "Zero length comment encountered: W613401,W23204,W75392\n",
      "Zero length comment encountered: W82756,W279684\n",
      "Zero length comment encountered: W34269,W35320\n",
      "Zero length comment encountered: W77693,W14374\n",
      "Zero length comment encountered: W79687,W44392\n",
      "Zero length comment encountered: W98189\n",
      "Zero length comment encountered: W84664\n",
      "Zero length comment encountered: W88142\n",
      "Zero length comment encountered: W37218\n",
      "Zero length comment encountered: W150441\n",
      "Zero length comment encountered: W882424\n",
      "Zero length comment encountered: W32351,W99555,W62097\n",
      "Zero length comment encountered: W140045,W213448,W140045\n",
      "Zero length comment encountered: W40830\n",
      "Zero length comment encountered: W305051\n",
      "Zero length comment encountered: W36253,W525182,W877790\n",
      "Zero length comment encountered: W78073,W11322\n",
      "Zero length comment encountered: W128778\n",
      "Zero length comment encountered: W695393\n",
      "Zero length comment encountered: W23809\n",
      "Zero length comment encountered: W210095\n",
      "Zero length comment encountered: W31923,W200505\n",
      "Zero length comment encountered: W76172\n",
      "Zero length comment encountered: W303179,W385878\n",
      "Zero length comment encountered: W56000,W22081\n",
      "Zero length comment encountered: W10246\n",
      "Zero length comment encountered: W107871,W87005,W125676\n",
      "Zero length comment encountered: W60062\n",
      "Zero length comment encountered: W16002\n",
      "Zero length comment encountered: W168488\n",
      "Zero length comment encountered: W271626\n",
      "Zero length comment encountered: W110179,W222230,W103006\n",
      "Zero length comment encountered: W40704\n",
      "Zero length comment encountered: W34371\n",
      "Zero length comment encountered: W14203\n",
      "Zero length comment encountered: W236672,W91543\n",
      "Zero length comment encountered: W45104\n",
      "Zero length comment encountered: W58083,W35003\n",
      "Zero length comment encountered: W481474\n",
      "Zero length comment encountered: W32182,W8899\n",
      "Zero length comment encountered: W64567\n",
      "Zero length comment encountered: W21537\n",
      "Zero length comment encountered: W76670,W93034\n",
      "Zero length comment encountered: W15844\n",
      "Zero length comment encountered: W285915\n",
      "Zero length comment encountered: W35834\n",
      "Zero length comment encountered: W39328,W159833\n",
      "Zero length comment encountered: W299258\n",
      "Zero length comment encountered: W610462\n",
      "Zero length comment encountered: W45386\n",
      "Zero length comment encountered: W134954\n",
      "Zero length comment encountered: W73613,W35530,W106262\n",
      "Zero length comment encountered: W78075\n",
      "Zero length comment encountered: W107251,W128545,W23413\n",
      "Zero length comment encountered: W372714,W293732\n",
      "Zero length comment encountered: W37987\n",
      "Zero length comment encountered: W65562\n",
      "Zero length comment encountered: W81935,W25901\n",
      "Zero length comment encountered: W72436\n",
      "Zero length comment encountered: W68313\n",
      "Zero length comment encountered: W113245\n",
      "Zero length comment encountered: W49652,W62221,W56467\n",
      "Zero length comment encountered: W109801\n",
      "Zero length comment encountered: W103152,W23344\n",
      "Zero length comment encountered: W34598,W11447,W97698\n",
      "Zero length comment encountered: W383741\n",
      "Zero length comment encountered: W34822,W48544\n",
      "Zero length comment encountered: W25466\n",
      "Zero length comment encountered: W40246,W111474,W78206\n",
      "Zero length comment encountered: W26536\n",
      "Zero length comment encountered: W18944,W396518\n",
      "Zero length comment encountered: W7647\n",
      "Zero length comment encountered: W22280,W48459,W23047\n",
      "Zero length comment encountered: W12678\n",
      "Zero length comment encountered: W145000\n",
      "Zero length comment encountered: W41899,W56159,W31503\n",
      "Zero length comment encountered: W35448,W522868\n",
      "Zero length comment encountered: W45845,W349744\n",
      "Zero length comment encountered: W21306,W21384\n",
      "Zero length comment encountered: W42296\n",
      "Zero length comment encountered: W92571\n",
      "Zero length comment encountered: W47442\n",
      "Zero length comment encountered: W88139,W152923\n",
      "Zero length comment encountered: W46251,W53686\n",
      "Zero length comment encountered: W113499\n",
      "Zero length comment encountered: W131905\n",
      "Zero length comment encountered: W11737\n",
      "Zero length comment encountered: W90321\n",
      "Zero length comment encountered: W35293,W74066\n",
      "Zero length comment encountered: W104268\n",
      "Zero length comment encountered: W50638,W16365,W6811,W16365\n",
      "Zero length comment encountered: W54870,W15512,W78603,W33185,W141047,W15512\n",
      "Zero length comment encountered: W20232\n",
      "Zero length comment encountered: W17318,W194863,W82109,W12956\n",
      "Zero length comment encountered: W50345,W13411\n",
      "Zero length comment encountered: W33179\n",
      "Zero length comment encountered: W160116,W47364,W32025\n",
      "Zero length comment encountered: W24702,W17292\n",
      "Zero length comment encountered: W153132\n",
      "Zero length comment encountered: W19559,W19559,W19559,W19559\n",
      "Zero length comment encountered: W12575,W640966,W28425,W36657\n",
      "Zero length comment encountered: W52551,W65769\n",
      "Zero length comment encountered: W18438\n",
      "Zero length comment encountered: W288365\n",
      "Zero length comment encountered: W49841,W104604,W68435,W262053\n",
      "Zero length comment encountered: W8337\n",
      "Zero length comment encountered: W51043,W45496\n",
      "Zero length comment encountered: W30106\n",
      "Zero length comment encountered: W120493\n",
      "Zero length comment encountered: W161561,W268223,W281849\n",
      "Zero length comment encountered: W385557,W550523,W89148\n",
      "Zero length comment encountered: W193696,W31652\n",
      "Zero length comment encountered: W74718\n",
      "Zero length comment encountered: W141324,W49865,W1321889\n",
      "Zero length comment encountered: W49326\n",
      "Zero length comment encountered: W233053,W185338\n",
      "Zero length comment encountered: W212111,W41067\n",
      "Zero length comment encountered: W33549,W116003,W47953,W56470\n",
      "Zero length comment encountered: W62198\n",
      "Zero length comment encountered: W146940,W60684\n",
      "Zero length comment encountered: W39640\n",
      "Zero length comment encountered: W15736,W82280\n",
      "Zero length comment encountered: W155064\n",
      "Zero length comment encountered: W30219,W23747\n",
      "Zero length comment encountered: W50115\n",
      "Zero length comment encountered: W41808\n",
      "Zero length comment encountered: W76612\n",
      "Zero length comment encountered: W24262\n",
      "Zero length comment encountered: W17091,W18595\n",
      "Zero length comment encountered: W27401,W241681,W178683,W280061\n",
      "Zero length comment encountered: W50000\n",
      "Zero length comment encountered: W60336\n",
      "Zero length comment encountered: W65775\n",
      "Zero length comment encountered: W121788\n",
      "Zero length comment encountered: W94579,W61080\n",
      "Zero length comment encountered: W8276,W48133\n",
      "Zero length comment encountered: W23712,W37811,W155475\n",
      "Zero length comment encountered: W279684,W33577\n",
      "Zero length comment encountered: W118520,W67252,W185901\n",
      "Zero length comment encountered: W17011,W17011\n",
      "Zero length comment encountered: W23843,W38148\n",
      "Zero length comment encountered: W108840,W37429\n",
      "Zero length comment encountered: W13042\n",
      "Zero length comment encountered: W39910,W53744\n",
      "Zero length comment encountered: W94403,W75368,W34346\n",
      "Zero length comment encountered: W19337,W45408,W80893\n",
      "Zero length comment encountered: W20628\n",
      "Zero length comment encountered: W167864,W181367,W28357,W47207,W28357\n",
      "Zero length comment encountered: W915585\n",
      "Zero length comment encountered: W36331,W170943\n",
      "Zero length comment encountered: W228431,W57254\n",
      "Zero length comment encountered: W41257\n",
      "Zero length comment encountered: W22075\n",
      "Zero length comment encountered: W70945\n",
      "Zero length comment encountered: W16539,W56278\n",
      "Zero length comment encountered: W93419,W222492\n",
      "Zero length comment encountered: W104305,W83315\n",
      "Zero length comment encountered: W41531\n",
      "Zero length comment encountered: W78755\n",
      "Zero length comment encountered: W32052,W34974,W290664,W49023,W15693\n",
      "Zero length comment encountered: W456667,W456667\n",
      "Zero length comment encountered: W105515,W234842\n",
      "Zero length comment encountered: W161274,W94751,W109957\n",
      "Zero length comment encountered: W48092\n",
      "Zero length comment encountered: W63872\n",
      "Zero length comment encountered: W9683\n",
      "Zero length comment encountered: W79417\n",
      "Zero length comment encountered: W30654,W19210,W65101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W106198\n",
      "Zero length comment encountered: W182599\n",
      "Zero length comment encountered: W117941,W116464\n",
      "Zero length comment encountered: W105205\n",
      "Zero length comment encountered: W110772,W31652,W31652\n",
      "Zero length comment encountered: W275404\n",
      "Zero length comment encountered: W124680\n",
      "Zero length comment encountered: W67115,W186251\n",
      "Zero length comment encountered: W89056\n",
      "Zero length comment encountered: W83097\n",
      "Zero length comment encountered: W1022737,W24956,W72104\n",
      "Zero length comment encountered: W60327,W60327,W60327\n",
      "Zero length comment encountered: W477288,W370222,W90163\n",
      "Zero length comment encountered: W85396\n",
      "Zero length comment encountered: W140837\n",
      "Zero length comment encountered: W45155,W45155,W41244\n",
      "Zero length comment encountered: W50973\n",
      "Zero length comment encountered: W270551\n",
      "Zero length comment encountered: W41570\n",
      "Zero length comment encountered: W47981,W54854\n",
      "Zero length comment encountered: W67219,W47036,W36754,W63714,W76946,W56695,W51510\n",
      "Zero length comment encountered: W270779\n",
      "Zero length comment encountered: W134722,W14286\n",
      "Zero length comment encountered: W55984,W23021\n",
      "Zero length comment encountered: W127747,W31375,W69220\n",
      "Zero length comment encountered: W50211,W29513\n",
      "Zero length comment encountered: W80110,W42432\n",
      "Zero length comment encountered: W53935\n",
      "Zero length comment encountered: W92028\n",
      "Zero length comment encountered: W28563,W129210\n",
      "Zero length comment encountered: W891286\n",
      "Zero length comment encountered: W16117\n",
      "Zero length comment encountered: W19927\n",
      "Zero length comment encountered: W97424,W97424\n",
      "Zero length comment encountered: W35560,W37270\n",
      "Zero length comment encountered: W153889,W83997\n",
      "Zero length comment encountered: W216223,W63310,W59737\n",
      "Zero length comment encountered: W55677\n",
      "Zero length comment encountered: W134499,W275535\n",
      "Zero length comment encountered: W15568\n",
      "Zero length comment encountered: W31738\n",
      "Zero length comment encountered: W158408,W31274\n",
      "Zero length comment encountered: W64407\n",
      "Zero length comment encountered: W73763,W119930,W28643\n",
      "Zero length comment encountered: W16635,W563304,W1464011\n",
      "Zero length comment encountered: W62088,W62088\n",
      "Zero length comment encountered: W125597\n",
      "Zero length comment encountered: W26762,W41256\n",
      "Zero length comment encountered: W122981,W143821,W14973\n",
      "Zero length comment encountered: W53749,W61118,W39974\n",
      "Zero length comment encountered: W37574,W129294,W218000,W129294\n",
      "Zero length comment encountered: W162752\n",
      "Zero length comment encountered: W157492\n",
      "Zero length comment encountered: W27423\n",
      "Zero length comment encountered: W25583,W230393\n",
      "Zero length comment encountered: W71700,W18317\n",
      "Zero length comment encountered: W127836,W293481,W99495\n",
      "Zero length comment encountered: W92608,W117002\n",
      "Zero length comment encountered: W48231,W48231\n",
      "Zero length comment encountered: W14717,W145985\n",
      "Zero length comment encountered: W22403,W38354\n",
      "Zero length comment encountered: W452339\n",
      "Zero length comment encountered: W77228,W44343,W59351\n",
      "Zero length comment encountered: W34445\n",
      "Zero length comment encountered: W206750\n",
      "Zero length comment encountered: W130835,W28944\n",
      "Zero length comment encountered: W49689,W96177\n",
      "Zero length comment encountered: W35189,W64396,W40930\n",
      "Zero length comment encountered: W71786\n",
      "Zero length comment encountered: W78217\n",
      "Zero length comment encountered: W49126,W86532\n",
      "Zero length comment encountered: W229566\n",
      "Zero length comment encountered: W12438\n",
      "Zero length comment encountered: W51851\n",
      "Zero length comment encountered: W33953\n",
      "Zero length comment encountered: W130909,W103131,W53362,W40826\n",
      "Zero length comment encountered: W10897,W20502\n",
      "Zero length comment encountered: W10610\n",
      "Zero length comment encountered: W107690\n",
      "Zero length comment encountered: W41616,W50864\n",
      "Zero length comment encountered: W237712\n",
      "Zero length comment encountered: W361005,W307012,W39310\n",
      "Zero length comment encountered: W40522,W42917\n",
      "Zero length comment encountered: W55509,W92369\n",
      "Zero length comment encountered: W43258,W54091\n",
      "Zero length comment encountered: W113222,W96008,W46227,W462876,W160132,W57991\n",
      "Zero length comment encountered: W52381\n",
      "Zero length comment encountered: W38221\n",
      "Zero length comment encountered: W21064,W10473\n",
      "Zero length comment encountered: W75467,W109361,W84237\n",
      "Zero length comment encountered: W110862\n",
      "Zero length comment encountered: W65163,W184883\n",
      "Zero length comment encountered: W201883\n",
      "Zero length comment encountered: W138175\n",
      "Zero length comment encountered: W21917,W50753\n",
      "Zero length comment encountered: W72143\n",
      "Zero length comment encountered: W37567,W73585,W43439,W37567\n",
      "Zero length comment encountered: W65639,W29611\n",
      "Zero length comment encountered: W88031\n",
      "Zero length comment encountered: W19927,W19927\n",
      "Zero length comment encountered: W9258,W110132,W54795,W70046,W7128,W20788\n",
      "Zero length comment encountered: W23661,W22340\n",
      "Zero length comment encountered: W162299\n",
      "Zero length comment encountered: W154187,W158180\n",
      "Zero length comment encountered: W70418,W31313,W39310\n",
      "Zero length comment encountered: W170285,W425467\n",
      "Zero length comment encountered: W53922,W236812\n",
      "Zero length comment encountered: W324204\n",
      "Zero length comment encountered: W32354\n",
      "Zero length comment encountered: W286662,W102125,W76694\n",
      "Zero length comment encountered: W70328,W34628,W119526\n",
      "Zero length comment encountered: W21790,W26184\n",
      "Zero length comment encountered: W41858\n",
      "Zero length comment encountered: W14350,W138020\n",
      "Zero length comment encountered: W138979\n",
      "Zero length comment encountered: W150702,W196210\n",
      "Zero length comment encountered: W157826\n",
      "Zero length comment encountered: W68367,W14609\n",
      "Zero length comment encountered: W40637\n",
      "Zero length comment encountered: W3447,W41854\n",
      "Zero length comment encountered: W360269,W41288,W58753\n",
      "Zero length comment encountered: W88570\n",
      "Zero length comment encountered: W38184,W90073\n",
      "Zero length comment encountered: W50855\n",
      "Zero length comment encountered: W54533,W34677\n",
      "Zero length comment encountered: W45044\n",
      "Zero length comment encountered: W47938,W123981\n",
      "Zero length comment encountered: W77854\n",
      "Zero length comment encountered: W86328,W134926\n",
      "Zero length comment encountered: W162876,W514340\n",
      "Zero length comment encountered: W186246,W103996\n",
      "Zero length comment encountered: W81957,W85585\n",
      "Zero length comment encountered: W9666\n",
      "Zero length comment encountered: W78117\n",
      "Zero length comment encountered: W22014\n",
      "Zero length comment encountered: W177156,W35349,W500538\n",
      "Zero length comment encountered: W418248,W99030\n",
      "Zero length comment encountered: W28523,W43804\n",
      "Zero length comment encountered: W152108,W80358\n",
      "Zero length comment encountered: W48748,W6933,W35182\n",
      "Zero length comment encountered: W67411,W261809\n",
      "Zero length comment encountered: W72424,W62551\n",
      "Zero length comment encountered: W85910\n",
      "Zero length comment encountered: W26988\n",
      "Zero length comment encountered: W9851\n",
      "Zero length comment encountered: W1053415,W86004,W14599\n",
      "Zero length comment encountered: W43372\n",
      "Zero length comment encountered: W26045,W18518,W22873\n",
      "Zero length comment encountered: W42395,W63470\n",
      "Zero length comment encountered: W272185,W36056,W74004,W66872\n",
      "Zero length comment encountered: W16416,W189838\n",
      "Zero length comment encountered: W61935,W60394\n",
      "Zero length comment encountered: W1129680,W285573\n",
      "Zero length comment encountered: W17113\n",
      "Zero length comment encountered: W44424,W39528\n",
      "Zero length comment encountered: W62992,W15340\n",
      "Zero length comment encountered: W69464\n",
      "Zero length comment encountered: W13006\n",
      "Zero length comment encountered: W22765\n",
      "Zero length comment encountered: W8945,W56214\n",
      "Zero length comment encountered: W16820\n",
      "Zero length comment encountered: W10473,W43072\n",
      "Zero length comment encountered: W31967\n",
      "Zero length comment encountered: W89045,W248078\n",
      "Zero length comment encountered: W102431,W86909\n",
      "Zero length comment encountered: W227167,W23350\n",
      "Zero length comment encountered: W68382\n",
      "Zero length comment encountered: W13007,W13007\n",
      "Zero length comment encountered: W30425,W27296\n",
      "Zero length comment encountered: W61423\n",
      "Zero length comment encountered: W117090\n",
      "Zero length comment encountered: W1035414\n",
      "Zero length comment encountered: W290590,W481934\n",
      "Zero length comment encountered: W72748,W212100,W25880\n",
      "Zero length comment encountered: W70999,W82396,W12753\n",
      "Zero length comment encountered: W336369\n",
      "Zero length comment encountered: W237715,W101358\n",
      "Zero length comment encountered: W44780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W43377\n",
      "Zero length comment encountered: W122159\n",
      "Zero length comment encountered: W917653\n",
      "Zero length comment encountered: W86896\n",
      "Zero length comment encountered: W107891,W150483,W43598,W80927,W61457\n",
      "Zero length comment encountered: W58482\n",
      "Zero length comment encountered: W30132,W196627,W128442\n",
      "Zero length comment encountered: W84555,W358420\n",
      "Zero length comment encountered: W41727\n",
      "Zero length comment encountered: W215122\n",
      "Zero length comment encountered: W386079,W54909\n",
      "Zero length comment encountered: W142294,W25783\n",
      "Zero length comment encountered: W36535\n",
      "Zero length comment encountered: W178779\n",
      "Zero length comment encountered: W90618\n",
      "Zero length comment encountered: W44367\n",
      "Zero length comment encountered: W42937\n",
      "Zero length comment encountered: W32061\n",
      "Zero length comment encountered: W48166,W14233,W38096\n",
      "Zero length comment encountered: W157158,W136954\n",
      "Zero length comment encountered: W73302,W180532,W811348,W794309\n",
      "Zero length comment encountered: W66041\n",
      "Zero length comment encountered: W32419,W71125,W137793,W18821,W176250\n",
      "Zero length comment encountered: W125821,W235678\n",
      "Zero length comment encountered: W13187\n",
      "Zero length comment encountered: W1093246\n",
      "Zero length comment encountered: W21816,W29160,W10631\n",
      "Zero length comment encountered: W33179\n",
      "Zero length comment encountered: W44039,W179358,W49698,W35437,W273694\n",
      "Zero length comment encountered: W119763\n",
      "Zero length comment encountered: W102876\n",
      "Zero length comment encountered: W120825,W59608\n",
      "Zero length comment encountered: W10026,W10026\n",
      "Zero length comment encountered: W28618,W81367,W150361\n",
      "Zero length comment encountered: W159860\n",
      "Zero length comment encountered: W4302\n",
      "Zero length comment encountered: W92428,W186108,W137359,W65178\n",
      "Zero length comment encountered: W34991\n",
      "Zero length comment encountered: W44708,W105477\n",
      "Zero length comment encountered: W103749\n",
      "Zero length comment encountered: W15033,W105075,W34200,W304536,W102192\n",
      "Zero length comment encountered: W25182\n",
      "Zero length comment encountered: W90389,W902774,W581627\n",
      "Zero length comment encountered: W39592\n",
      "Zero length comment encountered: W52722,W18256,W46269,W572226\n",
      "Zero length comment encountered: W309129,W146315\n",
      "Zero length comment encountered: W86196\n",
      "Zero length comment encountered: W111429,W8215\n",
      "Zero length comment encountered: W86826\n",
      "Zero length comment encountered: W801324,W445831\n",
      "Zero length comment encountered: W148910,W230983\n",
      "Zero length comment encountered: W240042,W12306,W17933\n",
      "Zero length comment encountered: W38176,W21614\n",
      "Zero length comment encountered: W40999,W74576\n",
      "Zero length comment encountered: W40682\n",
      "Zero length comment encountered: W22899\n",
      "Zero length comment encountered: W44937\n",
      "Zero length comment encountered: W26426\n",
      "Zero length comment encountered: W72460,W211697,W98122\n",
      "Zero length comment encountered: W9490,W27076,W118279\n",
      "Zero length comment encountered: W246179,W188849,W246179\n",
      "Zero length comment encountered: W32627\n",
      "Zero length comment encountered: W31146,W192221\n",
      "Zero length comment encountered: W660724,W71470\n",
      "Zero length comment encountered: W20288\n",
      "Zero length comment encountered: W45037,W56502,W51206,W42541,W64584,W48306,W64445,W6811,W73337\n",
      "Zero length comment encountered: W45656,W60332,W22354,W320830,W50291\n",
      "Zero length comment encountered: W118081\n",
      "Zero length comment encountered: W44957\n",
      "Zero length comment encountered: W38907,W20670\n",
      "Zero length comment encountered: W147720,W10165,W48231\n",
      "Zero length comment encountered: W59310\n",
      "Zero length comment encountered: W76023\n",
      "Zero length comment encountered: W130835\n",
      "Zero length comment encountered: W18372,W23829,W41403\n",
      "Zero length comment encountered: W6418\n",
      "Zero length comment encountered: W162439\n",
      "Zero length comment encountered: W68762,W50507\n",
      "Zero length comment encountered: W116313\n",
      "Zero length comment encountered: W15644\n",
      "Zero length comment encountered: W30155,W95666\n",
      "Zero length comment encountered: W59100,W230087\n",
      "Zero length comment encountered: W88998\n",
      "Zero length comment encountered: W166826,W57829,W39343\n",
      "Zero length comment encountered: W47420\n",
      "Zero length comment encountered: W51351\n",
      "Zero length comment encountered: W112873\n",
      "Zero length comment encountered: W13982\n",
      "Zero length comment encountered: W110979\n",
      "Zero length comment encountered: W12130,W18861\n",
      "Zero length comment encountered: W88797,W208294\n",
      "Zero length comment encountered: W30219,W123921\n",
      "Zero length comment encountered: W255180,W27010\n",
      "Zero length comment encountered: W500686,W254330\n",
      "Zero length comment encountered: W15867\n",
      "Zero length comment encountered: W91320,W10721\n",
      "Zero length comment encountered: W19520,W88842,W52329\n",
      "Zero length comment encountered: W29580,W35217\n",
      "Zero length comment encountered: W48657\n",
      "Zero length comment encountered: W9718,W9718\n",
      "Zero length comment encountered: W39008,W22237\n",
      "Zero length comment encountered: W57180,W16684,W58460\n",
      "Zero length comment encountered: W28751,W182394\n",
      "Zero length comment encountered: W49092\n",
      "Zero length comment encountered: W439282,W491899,W491899,W764513,W465741,W491899,W415930,W405946,W69511,W405946,W439282\n",
      "Zero length comment encountered: W619789\n",
      "Zero length comment encountered: W121249,W21695,W17355\n",
      "Zero length comment encountered: W322170,W113640,W20670\n",
      "Zero length comment encountered: W591472,W77138\n",
      "Zero length comment encountered: W53902,W67280\n",
      "Zero length comment encountered: W23929\n",
      "Zero length comment encountered: W154027,W256121\n",
      "Zero length comment encountered: W50145\n",
      "Zero length comment encountered: W69456\n",
      "Zero length comment encountered: W19250\n",
      "Zero length comment encountered: W183107\n",
      "Zero length comment encountered: W7355\n",
      "Zero length comment encountered: W89377\n",
      "Zero length comment encountered: W27301,W79104\n",
      "Zero length comment encountered: W50115,W132252,W157396\n",
      "Zero length comment encountered: W1086891\n",
      "Zero length comment encountered: W356917,W27827\n",
      "Zero length comment encountered: W51736,W17968\n",
      "Zero length comment encountered: W560197,W103862,W43881\n",
      "Zero length comment encountered: W108854\n",
      "Zero length comment encountered: W48881,W39888\n",
      "Zero length comment encountered: W89130,W116029,W189040\n",
      "Zero length comment encountered: W120148,W51918\n",
      "Zero length comment encountered: W43993,W56754\n",
      "Zero length comment encountered: W33322\n",
      "Zero length comment encountered: W19927,W21902\n",
      "Zero length comment encountered: W21518\n",
      "Zero length comment encountered: W20852\n",
      "Zero length comment encountered: W207562,W48968\n",
      "Zero length comment encountered: W183732\n",
      "Zero length comment encountered: W11282,W67055,W104502,W11282\n",
      "Zero length comment encountered: W539018,W22734\n",
      "Zero length comment encountered: W136889,W56017\n",
      "Zero length comment encountered: W109806\n",
      "Zero length comment encountered: W35902,W67942\n",
      "Zero length comment encountered: W219599,W68597,W19963,W93758\n",
      "Zero length comment encountered: W20533,W24559\n",
      "Zero length comment encountered: W37148\n",
      "Zero length comment encountered: W38582\n",
      "Zero length comment encountered: W7647,W7533\n",
      "Zero length comment encountered: W5192\n",
      "Zero length comment encountered: W61305,W173329\n",
      "Zero length comment encountered: W100849\n",
      "Zero length comment encountered: W23789,W37894,W30381\n",
      "Zero length comment encountered: W26709\n",
      "Zero length comment encountered: W60159,W12740\n",
      "Zero length comment encountered: W37273,W86569,W44937\n",
      "Zero length comment encountered: W234838,W605132\n",
      "Zero length comment encountered: W216534\n",
      "Zero length comment encountered: W633443\n",
      "Zero length comment encountered: W32169,W27566\n",
      "Zero length comment encountered: W158403,W69395\n",
      "Zero length comment encountered: W46428\n",
      "Zero length comment encountered: W128354,W841007\n",
      "Zero length comment encountered: W43680,W13578\n",
      "Zero length comment encountered: W143770\n",
      "Zero length comment encountered: W159431,W105224\n",
      "Zero length comment encountered: W100591,W310856\n",
      "Zero length comment encountered: W110908,W255732,W110908,W150971\n",
      "Zero length comment encountered: W66951,W228408,W18426\n",
      "Zero length comment encountered: W457388,W51319\n",
      "Zero length comment encountered: W17356,W92084,W40129\n",
      "Zero length comment encountered: W311381,W11728\n",
      "Zero length comment encountered: W608701\n",
      "Zero length comment encountered: W21907\n",
      "Zero length comment encountered: W252713,W143597,W179999,W205250,W146751\n",
      "Zero length comment encountered: W25575\n",
      "Zero length comment encountered: W36639\n",
      "Zero length comment encountered: W100567\n",
      "Zero length comment encountered: W63234\n",
      "Zero length comment encountered: W28907\n",
      "Zero length comment encountered: W167270,W87381\n",
      "Zero length comment encountered: W301533,W113803\n",
      "Zero length comment encountered: W24844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W54089,W38816,W54089,W38816\n",
      "Zero length comment encountered: W36280,W226722\n",
      "Zero length comment encountered: W15878\n",
      "Zero length comment encountered: W115796\n",
      "Zero length comment encountered: W112288,W29649\n",
      "Zero length comment encountered: W332779\n",
      "Zero length comment encountered: W208695,W119960\n",
      "Zero length comment encountered: W39497,W25298\n",
      "Zero length comment encountered: W135383,W742939,W39973,W12516,W125838\n",
      "Zero length comment encountered: W17011,W17011,W17011,W17011\n",
      "Zero length comment encountered: W112873\n",
      "Zero length comment encountered: W50982,W59661,W50982,W88652\n",
      "Zero length comment encountered: W218021,W218021\n",
      "Zero length comment encountered: W5230\n",
      "Zero length comment encountered: W16561\n",
      "Zero length comment encountered: W35639,W33590\n",
      "Zero length comment encountered: W41830,W31326,W41830\n",
      "Zero length comment encountered: W3765\n",
      "Zero length comment encountered: W57422,W30328,W24388,W57422,W30328,W24388\n",
      "Zero length comment encountered: W71213\n",
      "Zero length comment encountered: W674920\n",
      "Zero length comment encountered: W124353\n",
      "Zero length comment encountered: W65048,W73191,W49378\n",
      "Zero length comment encountered: W80218,W495931,W36874\n",
      "Zero length comment encountered: W24320\n",
      "Zero length comment encountered: W103842\n",
      "Zero length comment encountered: W18096,W70737\n",
      "Zero length comment encountered: W84563,W53732\n",
      "Zero length comment encountered: W174957,W54120\n",
      "Zero length comment encountered: W8058,W14766\n",
      "Zero length comment encountered: W34110\n",
      "Zero length comment encountered: W25590\n",
      "Zero length comment encountered: W140163,W144695\n",
      "Zero length comment encountered: W85703,W30564\n",
      "Zero length comment encountered: W78291,W15170,W90442,W50764,W695325\n",
      "Zero length comment encountered: W45104,W53256\n",
      "Zero length comment encountered: W49858\n",
      "Zero length comment encountered: W68854\n",
      "Zero length comment encountered: W117614,W300864\n",
      "Zero length comment encountered: W22222\n",
      "Zero length comment encountered: W13042,W36727\n",
      "Zero length comment encountered: W50749,W60155,W44555\n",
      "Zero length comment encountered: W183680,W116466\n",
      "Zero length comment encountered: W39999\n",
      "Zero length comment encountered: W61892,W33219\n",
      "Zero length comment encountered: W108406,W147623\n",
      "Zero length comment encountered: W75117\n",
      "Zero length comment encountered: W73612\n",
      "Zero length comment encountered: W102418,W12049\n",
      "Zero length comment encountered: W57822\n",
      "Zero length comment encountered: W74009,W43555,W73060,W73888,W37072\n",
      "Zero length comment encountered: W376130\n",
      "Zero length comment encountered: W1375772\n",
      "Zero length comment encountered: W130530\n",
      "Zero length comment encountered: W25807\n",
      "Zero length comment encountered: W37610,W213918\n",
      "Zero length comment encountered: W116248,W15449\n",
      "Zero length comment encountered: W28771\n",
      "Zero length comment encountered: W79727\n",
      "Zero length comment encountered: W61298\n",
      "Zero length comment encountered: W10540,W16567\n",
      "Zero length comment encountered: W10540,W16567\n",
      "Zero length comment encountered: W30262,W25413\n",
      "Zero length comment encountered: W93223,W119248,W257859,W12234\n",
      "Zero length comment encountered: W174264,W27754,W61443\n",
      "Zero length comment encountered: W28873\n",
      "Zero length comment encountered: W53521,W18144\n",
      "Zero length comment encountered: W73873,W80916,W131115\n",
      "Zero length comment encountered: W24606,W15556,W44041\n",
      "Zero length comment encountered: W115332\n",
      "Zero length comment encountered: W38338,W42427,W72661\n",
      "Zero length comment encountered: W194518,W161781\n",
      "Zero length comment encountered: W123139,W65263\n",
      "Zero length comment encountered: W120486\n",
      "Zero length comment encountered: W30072\n",
      "Zero length comment encountered: W72692,W208413\n",
      "Zero length comment encountered: W721459,W48773,W77551,W48773\n",
      "Zero length comment encountered: W64910,W24662\n",
      "Zero length comment encountered: W44923\n",
      "Zero length comment encountered: W34501,W77515\n",
      "Zero length comment encountered: W35007,W29118\n",
      "Zero length comment encountered: W10169\n",
      "Zero length comment encountered: W78985\n",
      "Zero length comment encountered: W186283,W31694\n",
      "Zero length comment encountered: W42668,W73351\n",
      "Zero length comment encountered: W28830,W154853,W15775\n",
      "Zero length comment encountered: W20241\n",
      "Zero length comment encountered: W21882\n",
      "Zero length comment encountered: W116090,W23720\n",
      "Zero length comment encountered: W200041\n",
      "Zero length comment encountered: W18682,W146641\n",
      "Zero length comment encountered: W20596\n",
      "Zero length comment encountered: W123114,W28935\n",
      "Zero length comment encountered: W78929,W251676\n",
      "Zero length comment encountered: W213270,W248604\n",
      "Zero length comment encountered: W457944,W50196,W52454\n",
      "Zero length comment encountered: W36801\n",
      "Zero length comment encountered: W71889,W22860\n",
      "Zero length comment encountered: W68177,W43529\n",
      "Zero length comment encountered: W147222\n",
      "Zero length comment encountered: W508162\n",
      "Zero length comment encountered: W13149\n",
      "Zero length comment encountered: W87044\n",
      "Zero length comment encountered: W280399,W121024\n",
      "Zero length comment encountered: W181844\n",
      "Zero length comment encountered: W34501,W27844\n",
      "Zero length comment encountered: W51206,W19209,W44557,W44557,W19209,W52307,W42541,W88733,W46897,W64445\n",
      "Zero length comment encountered: W151348,W475413,W44152\n",
      "Zero length comment encountered: W210915,W39700,W26085\n",
      "Zero length comment encountered: W126751\n",
      "Zero length comment encountered: W189846\n",
      "Zero length comment encountered: W65234\n",
      "Zero length comment encountered: W16702\n",
      "Zero length comment encountered: W21969\n",
      "Zero length comment encountered: W57297\n",
      "Zero length comment encountered: W65639,W20682\n",
      "Zero length comment encountered: W60100,W23424\n",
      "Zero length comment encountered: W50289,W5696\n",
      "Zero length comment encountered: W339851,W199599\n",
      "Zero length comment encountered: W105822,W41175\n",
      "Zero length comment encountered: W33324,W20387\n",
      "Zero length comment encountered: W16625,W55275,W41808\n",
      "Zero length comment encountered: W98288\n",
      "Zero length comment encountered: W23344,W339667\n",
      "Zero length comment encountered: W84073\n",
      "Zero length comment encountered: W356061,W44509\n",
      "Zero length comment encountered: W22270,W19560,W27247\n",
      "Zero length comment encountered: W47911,W187610,W109822\n",
      "Zero length comment encountered: W126923\n",
      "Zero length comment encountered: W19963,W21282\n",
      "Zero length comment encountered: W24427\n",
      "Zero length comment encountered: W244555,W354219\n",
      "Zero length comment encountered: W182484,W717138,W128719\n",
      "Zero length comment encountered: W43717\n",
      "Zero length comment encountered: W204958\n",
      "Zero length comment encountered: W198931,W328968,W44991,W85048\n",
      "Zero length comment encountered: W328309,W290241\n",
      "Zero length comment encountered: W63311,W89867,W97859\n",
      "Zero length comment encountered: W126553,W126553\n",
      "Zero length comment encountered: W264708,W81457\n",
      "Zero length comment encountered: W86648\n",
      "Zero length comment encountered: W125905\n",
      "Zero length comment encountered: W43123,W35178\n",
      "Zero length comment encountered: W16349,W16349\n",
      "Zero length comment encountered: W77430\n",
      "Zero length comment encountered: W68165,W73315,W26957\n",
      "Zero length comment encountered: W88739,W61892\n",
      "Zero length comment encountered: W65833,W15033\n",
      "Zero length comment encountered: W52837,W63412,W68439\n",
      "Zero length comment encountered: W20921,W137805,W172737\n",
      "Zero length comment encountered: W48138\n",
      "Zero length comment encountered: W94975\n",
      "Zero length comment encountered: W54682\n",
      "Zero length comment encountered: W102576,W458127\n",
      "Zero length comment encountered: W148718\n",
      "Zero length comment encountered: W37403,W47196\n",
      "Zero length comment encountered: W46162\n",
      "Zero length comment encountered: W60989,W58243\n",
      "Zero length comment encountered: W20133\n",
      "Zero length comment encountered: W960789,W26002\n",
      "Zero length comment encountered: W306775\n",
      "Zero length comment encountered: W31925,W51928\n",
      "Zero length comment encountered: W81219\n",
      "Zero length comment encountered: W324340,W73883\n",
      "Zero length comment encountered: W178777,W25834,W101643\n",
      "Zero length comment encountered: W57353\n",
      "Zero length comment encountered: W19038,W55652\n",
      "Zero length comment encountered: W60237\n",
      "Zero length comment encountered: W54324,W21782\n",
      "Zero length comment encountered: W100795\n",
      "Zero length comment encountered: W72436\n",
      "Zero length comment encountered: W66994\n",
      "Zero length comment encountered: W73223\n",
      "Zero length comment encountered: W32904\n",
      "Zero length comment encountered: W12237\n",
      "Zero length comment encountered: W107877,W61479\n",
      "Zero length comment encountered: W27751\n",
      "Zero length comment encountered: W109272,W152619\n",
      "Zero length comment encountered: W1367654\n",
      "Zero length comment encountered: W35042,W14940,W99891,W22521\n",
      "Zero length comment encountered: W295346\n",
      "Zero length comment encountered: W43173\n",
      "Zero length comment encountered: W122416\n",
      "Zero length comment encountered: W30801\n",
      "Zero length comment encountered: W27000,W36643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W50325\n",
      "Zero length comment encountered: W499154\n",
      "Zero length comment encountered: W57459,W63822\n",
      "Zero length comment encountered: W290263\n",
      "Zero length comment encountered: W200196\n",
      "Zero length comment encountered: W33819,W51289\n",
      "Zero length comment encountered: W90353,W58985\n",
      "Zero length comment encountered: W61687,W43607\n",
      "Zero length comment encountered: W198686,W58460\n",
      "Zero length comment encountered: W20884\n",
      "Zero length comment encountered: W17165,W19553\n",
      "Zero length comment encountered: W15293\n",
      "Zero length comment encountered: W17180,W26446\n",
      "Zero length comment encountered: W18709,W119188,W18709\n",
      "Zero length comment encountered: W256624\n",
      "Zero length comment encountered: W35078,W27301\n",
      "Zero length comment encountered: W43475,W29202,W13561,W45366\n",
      "Zero length comment encountered: W70737\n",
      "Zero length comment encountered: W39177\n",
      "Zero length comment encountered: W128044,W8801\n",
      "Zero length comment encountered: W20416\n",
      "Zero length comment encountered: W113953\n",
      "Zero length comment encountered: W121788,W85331,W45120\n",
      "Zero length comment encountered: W50096,W20810,W67444\n",
      "Zero length comment encountered: W225795,W57642,W149900\n",
      "Zero length comment encountered: W38120,W33376\n",
      "Zero length comment encountered: W20834\n",
      "Zero length comment encountered: W399965,W62321,W22314\n",
      "Zero length comment encountered: W81270,W69902\n",
      "Zero length comment encountered: W44664\n",
      "Zero length comment encountered: W22993,W74106,W22993,W84713\n",
      "Zero length comment encountered: W230502\n",
      "Zero length comment encountered: W105477\n",
      "Zero length comment encountered: W53886,W45645\n",
      "Zero length comment encountered: W25313\n",
      "Zero length comment encountered: W21805\n",
      "Zero length comment encountered: W31686,W16602\n",
      "Zero length comment encountered: W26772\n",
      "Zero length comment encountered: W72936,W40001\n",
      "Zero length comment encountered: W153255,W33485\n",
      "Zero length comment encountered: W89969\n",
      "Zero length comment encountered: W86002\n",
      "Zero length comment encountered: W150152\n",
      "Zero length comment encountered: W486105\n",
      "Zero length comment encountered: W214238,W44532,W22725\n",
      "Zero length comment encountered: W27365,W58118,W58118,W71743,W71743,W27365\n",
      "Zero length comment encountered: W40195\n",
      "Zero length comment encountered: W147826\n",
      "Zero length comment encountered: W23787,W12646\n",
      "Zero length comment encountered: W155285\n",
      "Zero length comment encountered: W53489,W257579,W39089\n",
      "Zero length comment encountered: W198686\n",
      "Zero length comment encountered: W647592,W35339\n",
      "Zero length comment encountered: W353655,W263043\n",
      "Zero length comment encountered: W27971\n",
      "Zero length comment encountered: W139667\n",
      "Zero length comment encountered: W104562\n",
      "Zero length comment encountered: W140251\n",
      "Zero length comment encountered: W57164,W88170\n",
      "Zero length comment encountered: W61202,W17151\n",
      "Zero length comment encountered: W32726,W48706\n",
      "Zero length comment encountered: W50577\n",
      "Zero length comment encountered: W30436,W87315\n",
      "Zero length comment encountered: W30823,W29126\n",
      "Zero length comment encountered: W23500,W16869\n",
      "Zero length comment encountered: W92581,W170628\n",
      "Zero length comment encountered: W16860,W97405,W35107\n",
      "Zero length comment encountered: W202617\n",
      "Zero length comment encountered: W28951,W26081,W71698,W11516\n",
      "Zero length comment encountered: W227461,W29170\n",
      "Zero length comment encountered: W30850\n",
      "Zero length comment encountered: W72593,W574472,W72593\n",
      "Zero length comment encountered: W18030,W18274,W22634\n",
      "Zero length comment encountered: W15642,W241385,W74931\n",
      "Zero length comment encountered: W90645\n",
      "Zero length comment encountered: W378611\n",
      "Zero length comment encountered: W17736,W29935,W126380\n",
      "Zero length comment encountered: W30658\n",
      "Zero length comment encountered: W40486,W154883\n",
      "Zero length comment encountered: W31665\n",
      "Zero length comment encountered: W401235\n",
      "Zero length comment encountered: W79416\n",
      "Zero length comment encountered: W226467\n",
      "Zero length comment encountered: W60787\n",
      "Zero length comment encountered: W25801\n",
      "Zero length comment encountered: W72145,W65470\n",
      "Zero length comment encountered: W21452\n",
      "Zero length comment encountered: W29269\n",
      "Zero length comment encountered: W81219,W85041\n",
      "Zero length comment encountered: W16689,W72880\n",
      "Zero length comment encountered: W94625\n",
      "Zero length comment encountered: W156362,W10284\n",
      "Zero length comment encountered: W47393\n",
      "Zero length comment encountered: W173767\n",
      "Zero length comment encountered: W109837\n",
      "Zero length comment encountered: W115932,W19677,W31764\n",
      "Zero length comment encountered: W63609\n",
      "Zero length comment encountered: W36237,W27885\n",
      "Zero length comment encountered: W110409,W303599\n",
      "Zero length comment encountered: W50702\n",
      "Zero length comment encountered: W57673,W31058\n",
      "Zero length comment encountered: W26961\n",
      "Zero length comment encountered: W34677\n",
      "Zero length comment encountered: W28177,W74311\n",
      "Zero length comment encountered: W229717,W15296\n",
      "Zero length comment encountered: W37433\n",
      "Zero length comment encountered: W53161,W19993\n",
      "Zero length comment encountered: W37140,W54406\n",
      "Zero length comment encountered: W279684\n",
      "Zero length comment encountered: W53000\n",
      "Zero length comment encountered: W99749,W71494\n",
      "Zero length comment encountered: W135679,W277409\n",
      "Zero length comment encountered: W333506,W25939\n",
      "Zero length comment encountered: W68006,W30119\n",
      "Zero length comment encountered: W281955\n",
      "Zero length comment encountered: W66785\n",
      "Zero length comment encountered: W21519,W29998,W38929\n",
      "Zero length comment encountered: W136275,W158860,W13859\n",
      "Zero length comment encountered: W63526\n",
      "Zero length comment encountered: W804496\n",
      "Zero length comment encountered: W111689,W49090\n",
      "Zero length comment encountered: W32852,W37731,W8496\n",
      "Zero length comment encountered: W39761,W25237\n",
      "Zero length comment encountered: W230637,W198671\n",
      "Zero length comment encountered: W53727\n",
      "Zero length comment encountered: W92680,W27556\n",
      "Zero length comment encountered: W78966,W10131,W112727\n",
      "Zero length comment encountered: W42453,W38094\n",
      "Zero length comment encountered: W126481,W173246\n",
      "Zero length comment encountered: W85769\n",
      "Zero length comment encountered: W77492\n",
      "Zero length comment encountered: W37645\n",
      "Zero length comment encountered: W44159\n",
      "Zero length comment encountered: W138768,W18499\n",
      "Zero length comment encountered: W815538,W322275,W227982\n",
      "Zero length comment encountered: W858566\n",
      "Zero length comment encountered: W17267\n",
      "Zero length comment encountered: W116560,W80144\n",
      "Zero length comment encountered: W436840,W38326,W42558\n",
      "Zero length comment encountered: W77541\n",
      "Zero length comment encountered: W12724\n",
      "Zero length comment encountered: W63880,W56263\n",
      "Zero length comment encountered: W45331\n",
      "Zero length comment encountered: W304531,W34894\n",
      "Zero length comment encountered: W119384\n",
      "Zero length comment encountered: W290093,W100619\n",
      "Zero length comment encountered: W28537\n",
      "Zero length comment encountered: W16587,W138618,W42910\n",
      "Zero length comment encountered: W31095\n",
      "Zero length comment encountered: W102069,W31529\n",
      "Zero length comment encountered: W38907,W20670\n",
      "Zero length comment encountered: W65129,W90392\n",
      "Zero length comment encountered: W44723,W45447\n",
      "Zero length comment encountered: W100707\n",
      "Zero length comment encountered: W109337,W12068\n",
      "Zero length comment encountered: W114329\n",
      "Zero length comment encountered: W255887\n",
      "Zero length comment encountered: W34307\n",
      "Zero length comment encountered: W266673,W25823\n",
      "Zero length comment encountered: W215126,W47730,W90804,W116204,W20558\n",
      "Zero length comment encountered: W50195\n",
      "Zero length comment encountered: W20837\n",
      "Zero length comment encountered: W12047\n",
      "Zero length comment encountered: W392339,W58357,W68121\n",
      "Zero length comment encountered: W101343,W13635\n",
      "Zero length comment encountered: W43121,W71713\n",
      "Zero length comment encountered: W65342,W101135,W153140\n",
      "Zero length comment encountered: W54389\n",
      "Zero length comment encountered: W48404\n",
      "Zero length comment encountered: W41901,W9940,W7358\n",
      "Zero length comment encountered: W185556\n",
      "Zero length comment encountered: W131226\n",
      "Zero length comment encountered: W9590,W124680\n",
      "Zero length comment encountered: W42859\n",
      "Zero length comment encountered: W516515\n",
      "Zero length comment encountered: W18795,W137852,W29967,W126999\n",
      "Zero length comment encountered: W69276\n",
      "Zero length comment encountered: W160436,W32540\n",
      "Zero length comment encountered: W56844,W119076,W86513\n",
      "Zero length comment encountered: W9590,W156362\n",
      "Zero length comment encountered: W79706\n",
      "Zero length comment encountered: W99403,W187220,W19047\n",
      "Zero length comment encountered: W52006\n",
      "Zero length comment encountered: W3447,W41854\n",
      "Zero length comment encountered: W82273\n",
      "Zero length comment encountered: W66070\n",
      "Zero length comment encountered: W184523,W12491,W30299\n",
      "Zero length comment encountered: W22340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero length comment encountered: W127715,W154098\n",
      "Zero length comment encountered: W96356,W71994,W41868,W25620\n",
      "Zero length comment encountered: W43266,W91764\n",
      "Zero length comment encountered: W55621,W77197,W637593,W132138\n",
      "Zero length comment encountered: W123627\n",
      "Zero length comment encountered: W215194,W215194\n",
      "Zero length comment encountered: W196402\n",
      "Zero length comment encountered: W50542\n",
      "Zero length comment encountered: W3175\n",
      "Zero length comment encountered: W84064,W20633\n",
      "Zero length comment encountered: W6592\n",
      "Zero length comment encountered: W32472\n",
      "Zero length comment encountered: W126898\n",
      "Zero length comment encountered: W59737,W74264\n",
      "Zero length comment encountered: W423723\n",
      "Zero length comment encountered: W36672,W36672\n",
      "Zero length comment encountered: W76670,W76670\n",
      "Zero length comment encountered: W114752\n",
      "Zero length comment encountered: W29214\n",
      "Zero length comment encountered: W33347,W85206\n",
      "Zero length comment encountered: W83517\n",
      "Zero length comment encountered: W59298\n",
      "Zero length comment encountered: W43258,W54091\n",
      "Zero length comment encountered: W543308\n",
      "Zero length comment encountered: W94388,W111834,W93133,W519857\n",
      "Zero length comment encountered: W93129,W18297\n",
      "Zero length comment encountered: W29715,W191949,W187059\n",
      "Zero length comment encountered: W164289,W163064,W271258,W40189,W66092,W29714,W549955\n",
      "Zero length comment encountered: W132010\n",
      "Zero length comment encountered: W45104\n",
      "Zero length comment encountered: W56296,W27106\n",
      "Zero length comment encountered: W1091586,W46157,W200399\n",
      "Zero length comment encountered: W160242,W131131\n",
      "Zero length comment encountered: W60455,W13185\n",
      "Zero length comment encountered: W444860,W245971\n",
      "Zero length comment encountered: W41113\n",
      "Zero length comment encountered: W74310,W238753\n",
      "Zero length comment encountered: W78851,W172185\n",
      "Zero length comment encountered: W12056,W119056\n",
      "Zero length comment encountered: W115816\n",
      "Zero length comment encountered: W62344\n",
      "Zero length comment encountered: W159188\n",
      "Zero length comment encountered: W28404\n",
      "Zero length comment encountered: W55935\n",
      "Zero length comment encountered: W14275,W26501\n",
      "Zero length comment encountered: W93998,W92244\n",
      "Zero length comment encountered: W49837,W34415\n",
      "Zero length comment encountered: W163862,W92583\n",
      "Zero length comment encountered: W1309349,W66108,W105831,W44078\n",
      "Zero length comment encountered: W66208\n",
      "Zero length comment encountered: W583725,W206599\n",
      "Zero length comment encountered: W122000\n",
      "Zero length comment encountered: W26568\n",
      "Zero length comment encountered: W6593\n",
      "Zero length comment encountered: W37161,W26459\n",
      "Zero length comment encountered: W101585\n",
      "Zero length comment encountered: W107690\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9a71b3e95e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVDSIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLsiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_corpuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, chunksize, decay, distributed, onepass, power_iters, extra_samples, dtype)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no word id mapping provided; initializing from corpus, assuming identity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_from_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mdict_from_corpus\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \"\"\"\n\u001b[0;32m--> 826\u001b[0;31m     \u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mget_max_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFakeDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mget_max_id\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \"\"\"\n\u001b[1;32m    733\u001b[0m     \u001b[0mmaxid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mmaxid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfieldid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-21e7c38c9965>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;31m# print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/models/tfidfmodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, eps)\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mnorm_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36munitvec\u001b[0;34m(vec, norm, return_norm)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'unique'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'unique'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf_corpuse = TFIDF_corpus(quest_df['title_W'], dictionary)\n",
    "\n",
    "embed_size = SVDSIZE\n",
    "lsi = LsiModel(tfidf_corpuse, num_topics= embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LsiModel in module gensim.models.lsimodel:\n",
      "\n",
      "class LsiModel(gensim.interfaces.TransformationABC, gensim.models.basemodel.BaseTopicModel)\n",
      " |  Model for `Latent Semantic Indexing\n",
      " |  <https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing>`_.\n",
      " |  \n",
      " |  The decomposition algorithm is described in `\"Fast and Faster: A Comparison of Two Streamed\n",
      " |  Matrix Decomposition Algorithms\" <https://nlp.fi.muni.cz/~xrehurek/nips/rehurek_nips.pdf>`_.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  * :attr:`gensim.models.lsimodel.LsiModel.projection.u` - left singular vectors,\n",
      " |  * :attr:`gensim.models.lsimodel.LsiModel.projection.s` - singular values,\n",
      " |  * ``model[training_corpus]`` - right singular vectors (can be reconstructed if needed).\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  `FAQ about LSI matrices\n",
      " |  <https://github.com/piskvorky/gensim/wiki/Recipes-&-FAQ#q4-how-do-you-output-the-u-s-vt-matrices-of-lsi>`_.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
      " |      >>> from gensim.models import LsiModel\n",
      " |      >>>\n",
      " |      >>> model = LsiModel(common_corpus[:3], id2word=common_dictionary)  # train model\n",
      " |      >>> vector = model[common_corpus[4]]  # apply model to BoW document\n",
      " |      >>> model.add_documents(common_corpus[4:])  # update model with new documents\n",
      " |      >>> tmp_fname = get_tmpfile(\"lsi.model\")\n",
      " |      >>> model.save(tmp_fname)  # save model\n",
      " |      >>> loaded_model = LsiModel.load(tmp_fname)  # load model\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LsiModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      gensim.models.basemodel.BaseTopicModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, bow, scaled=False, chunksize=512)\n",
      " |      Get the latent representation for `bow`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bow : {list of (int, int), iterable of list of (int, int)}\n",
      " |          Document or corpus in BoW representation.\n",
      " |      scaled : bool, optional\n",
      " |          If True - topics will be scaled by the inverse of singular values.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each applying chunk.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Latent representation of topics in BoW format for document **OR**\n",
      " |      :class:`gensim.matutils.Dense2Corpus`\n",
      " |          Latent representation of corpus in BoW format if `bow` is corpus.\n",
      " |  \n",
      " |  __init__(self, corpus=None, num_topics=200, id2word=None, chunksize=20000, decay=1.0, distributed=False, onepass=True, power_iters=2, extra_samples=100, dtype=<class 'numpy.float64'>)\n",
      " |      Construct an `LsiModel` object.\n",
      " |      \n",
      " |      Either `corpus` or `id2word` must be supplied in order to train the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`).\n",
      " |      num_topics : int, optional\n",
      " |          Number of requested factors (latent dimensions)\n",
      " |      id2word : dict of {int: str}, optional\n",
      " |          ID to word mapping, optional.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      decay : float, optional\n",
      " |          Weight of existing observations relatively to new ones.\n",
      " |      distributed : bool, optional\n",
      " |          If True - distributed mode (parallel execution on several machines) will be used.\n",
      " |      onepass : bool, optional\n",
      " |          Whether the one-pass algorithm should be used for training.\n",
      " |          Pass `False` to force a multi-pass stochastic algorithm.\n",
      " |      power_iters: int, optional\n",
      " |          Number of power iteration steps to be used.\n",
      " |          Increasing the number of power iterations improves accuracy, but lowers performance\n",
      " |      extra_samples : int, optional\n",
      " |          Extra samples to be used besides the rank `k`. Can improve accuracy.\n",
      " |      dtype : type, optional\n",
      " |          Enforces a type for elements of the decomposed matrix.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get a human readable representation of model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          A human readable string of the current objects parameters.\n",
      " |  \n",
      " |  add_documents(self, corpus, chunksize=None, decay=None)\n",
      " |      Update model with new `corpus`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, num_documents).\n",
      " |      chunksize : int, optional\n",
      " |          Number of documents to be used in each training chunk, will use `self.chunksize` if not specified.\n",
      " |      decay : float, optional\n",
      " |          Weight of existing observations relatively to new ones,  will use `self.decay` if not specified.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Training proceeds in chunks of `chunksize` documents at a time. The size of `chunksize` is a tradeoff\n",
      " |      between increased speed (bigger `chunksize`) vs. lower memory footprint (smaller `chunksize`).\n",
      " |      If the distributed mode is on, each chunk is sent to a different worker/computer.\n",
      " |  \n",
      " |  get_topics(self)\n",
      " |      Get the topic vectors.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The number of topics can actually be smaller than `self.num_topics`, if there were not enough factors\n",
      " |      in the matrix (real rank of input matrix smaller than `self.num_topics`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray\n",
      " |          The term topic matrix with shape (`num_topics`, `vocabulary_size`)\n",
      " |  \n",
      " |  print_debug(self, num_topics=5, num_words=10)\n",
      " |      Print (to log) the most salient words of the first `num_topics` topics.\n",
      " |      \n",
      " |      Unlike :meth:`~gensim.models.lsimodel.LsiModel.print_topics`, this looks for words that are significant for\n",
      " |      a particular topic *and* not for others. This *should* result in a\n",
      " |      more human-interpretable description of topics.\n",
      " |      \n",
      " |      Alias for :func:`~gensim.models.lsimodel.print_debug`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |  \n",
      " |  save(self, fname, *args, **kwargs)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Large internal arrays may be stored into separate files, with `fname` as prefix.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      Do not save as a compressed file if you intend to load the file back with `mmap`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to output file.\n",
      " |      *args\n",
      " |          Variable length argument list, see :meth:`gensim.utils.SaveLoad.save`.\n",
      " |      **kwargs\n",
      " |          Arbitrary keyword arguments, see :meth:`gensim.utils.SaveLoad.save`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.lsimodel.LsiModel.load`\n",
      " |  \n",
      " |  show_topic(self, topicno, topn=10)\n",
      " |      Get the words that define a topic along with their contribution.\n",
      " |      \n",
      " |      This is actually the left singular vector of the specified topic.\n",
      " |      \n",
      " |      The most important words in defining the topic (greatest absolute value) are included\n",
      " |      in the output, along with their contribution to the topic.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          The topics id number.\n",
      " |      topn : int\n",
      " |          Number of words to be included to the result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (str, float)\n",
      " |          Topic representation in BoW format.\n",
      " |  \n",
      " |  show_topics(self, num_topics=-1, num_words=10, log=False, formatted=True)\n",
      " |      Get the most significant topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      log : bool, optional\n",
      " |          If True - log topics with logger.\n",
      " |      formatted : bool, optional\n",
      " |          If True - each topic represented as string, otherwise - in BoW format.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, str)\n",
      " |          If `formatted=True`, return sequence with (topic_id, string representation of topics) **OR**\n",
      " |      list of (int, list of (str, float))\n",
      " |          Otherwise, return sequence with (topic_id, [(word, value), ... ]).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(fname, *args, **kwargs) from builtins.type\n",
      " |      Load a previously saved object using :meth:`~gensim.models.lsimodel.LsiModel.save` from file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Large arrays can be memmap'ed back as read-only (shared memory) by setting the `mmap='r'` parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file that contains LsiModel.\n",
      " |      *args\n",
      " |          Variable length argument list, see :meth:`gensim.utils.SaveLoad.load`.\n",
      " |      **kwargs\n",
      " |          Arbitrary keyword arguments, see :meth:`gensim.utils.SaveLoad.load`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.lsimodel.LsiModel.save`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~gensim.models.lsimodel.LsiModel`\n",
      " |          Loaded instance.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IOError\n",
      " |          When methods are called on instance (should be called from class).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.basemodel.BaseTopicModel:\n",
      " |  \n",
      " |  print_topic(self, topicno, topn=10)\n",
      " |      Get a single topic as a formatted string.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          Topic id.\n",
      " |      topn : int\n",
      " |          Number of words from topic that will be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          String representation of topic, like '-0.340 * \"category\" + 0.298 * \"$M$\" + 0.183 * \"algebra\" + ... '.\n",
      " |  \n",
      " |  print_topics(self, num_topics=20, num_words=10)\n",
      " |      Get the most significant topics (alias for `show_topics()` method).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, list of (str, float))\n",
      " |          Sequence with (topic_id, [(word, value), ... ]).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LsiModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "decomposition not initialized yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fc03f6f54e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_W'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, scaled, chunksize)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \"\"\"\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decomposition not initialized yet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# if the input vector is in fact a corpus, return a transformed corpus as a result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: decomposition not initialized yet"
     ]
    }
   ],
   "source": [
    "lsi[tfidf_model[dictionary.doc2bow(quest_df['title_W'].iloc[0].split(','))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_embd = map(lambda s: lsi[tfidf_model[dictionary.doc2bow(s.split(','))]], quest_df['title_W'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(quest_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}